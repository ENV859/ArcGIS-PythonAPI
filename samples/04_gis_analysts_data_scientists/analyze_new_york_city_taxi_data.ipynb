{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing New York City taxi data using big data tools\n",
    "\n",
    "At 10.5 and later releases, ArcGIS Enterprise introduces [ArcGIS GeoAnalytics Server](http://server.arcgis.com/en/server/latest/get-started/windows/what-is-arcgis-geoanalytics-server-.htm) which provides you the ability to perform big data analysis on your infrastructure. This sample demonstrates the steps involved in performing an aggregation analysis on New York city taxi point data using ArcGIS API for Python.\n",
    "\n",
    "The data used in this sample can be downloaded from [NYC Taxi & Limousine Commission website](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml). For this sample, data for the months January & Febuary of 2015 were used, each averaging 12 million records.\n",
    "\n",
    "**Note**: The ability to perform big data analysis is only available on ArcGIS Enterprise 10.5 licensed with a GeoAnalytics server and not yet available on ArcGIS Online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NYC taxi data\n",
    "\n",
    "To give you an overview, let us take a look at a subset with 2000 points published as a feature service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://www.arcgis.com/home/item.html?id=83d94a090176478f88843e5daf75e997' target='_blank'>\n",
       "                        <img src='https://www.arcgis.com/sharing/rest//content/items/83d94a090176478f88843e5daf75e997/info/thumbnail/thumbnail.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://www.arcgis.com/home/item.html?id=83d94a090176478f88843e5daf75e997' target='_blank'><b>NYC_taxi_subset</b>\n",
       "                        </a>\n",
       "                        <br/>A subset of NYC taxi data<img src='https://www.arcgis.com/home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\">Feature Layer Collection by atma.mani\n",
       "                        <br/>Last Modified: September 14, 2016\n",
       "                        <br/>0 comments, 827 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"NYC_taxi_subset\" type:Feature Layer Collection owner:atma.mani>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "\n",
    "ago_gis = GIS() # Connect to ArcGIS Online as an anonymous user\n",
    "search_subset = ago_gis.content.search(\"NYC_taxi_subset\", item_type = \"Feature Layer\")\n",
    "subset_item = search_subset[0]\n",
    "subset_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us bring up a map to display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_map = ago_gis.map(\"New York, NY\", zoomlevel=11)\n",
    "subset_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nyc_subset_img](http://esri.github.io/arcgis-python-api/notebooks/nbimages/04_AnalyzingNYCtaxi_01.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_map.add_layer(subset_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us access the feature layers using the `layers` property. We can select a specific layer from the laters list and explore its attribute table to understand the structure of our data. In the cell below, we use the feature layer's [`query()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.features.toc.html#arcgis.features.FeatureLayer.query) method to return the layer attribute information. The `query()` method returns a [`FeatureSet`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.features.toc.html#featureset) object, which is a collection of individual [`Feature`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.features.toc.html#feature) objects.\n",
    "\n",
    "You can mine through the `FeatureSet` to inspect each individual `Feature`, read its attribute information and then compose a table of all features and their attributes. However, the `FeatureSet` object provides a much easier and more direct way to get that information. Using the [`df`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.features.toc.html#arcgis.features.FeatureSet.df) property of a `FeatureSet`, you can load the attribute information as a [`pandas`](https://pandas.pydata.org/) [`dataframe`](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) object.\n",
    "\n",
    "If you installed the ArcGIS API for Python through ArcGIS Pro or with the `conda install` command, you have the api and its dependencies, including the `pandas` package. The [`df`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.features.toc.html#arcgis.features.FeatureSet.df) property will return a `dataframe`.  If you [installed without dependences](https://developers.arcgis.com/python/guide/install-and-set-up/#Install-without-Dependencies), you need to install the `pandas` Python package for the `df` property to return a dataframe. If you get an error that pandas cannot be found, you can install it by typing the following in your terminal that is running the jupyter notebook:\n",
    "\n",
    "    conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field1</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>RateCodeID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3479320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40.782318</td>\n",
       "      <td>-73.980492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.778149</td>\n",
       "      <td>-73.956291</td>\n",
       "      <td>N</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1970-01-01 00:23:42.268943</td>\n",
       "      <td>1970-01-01 00:23:42.268218</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8473342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40.769756</td>\n",
       "      <td>-73.950600</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>40.729458</td>\n",
       "      <td>-73.983864</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1970-01-01 00:23:42.137577</td>\n",
       "      <td>1970-01-01 00:23:42.136892</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10864374</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40.753040</td>\n",
       "      <td>-73.985680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>40.743740</td>\n",
       "      <td>-73.987617</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1970-01-01 00:23:42.719906</td>\n",
       "      <td>1970-01-01 00:23:42.718711</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7350094</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40.765743</td>\n",
       "      <td>-73.954994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>40.757507</td>\n",
       "      <td>-73.981682</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1970-01-01 00:23:40.907558</td>\n",
       "      <td>1970-01-01 00:23:40.906601</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Field1  OBJECTID  RateCodeID  VendorID  dropoff_latitude  \\\n",
       "0   3479320         1           1         2         40.782318   \n",
       "1   8473342         2           1         2         40.769756   \n",
       "2  10864374         3           1         2         40.753040   \n",
       "3   7350094         4           1         2         40.765743   \n",
       "\n",
       "   dropoff_longitude  extra  fare_amount  improvement_surcharge  mta_tax  \\\n",
       "0         -73.980492    0.0          9.5                    0.3      0.5   \n",
       "1         -73.950600    0.5         13.5                    0.3      0.5   \n",
       "2         -73.985680    0.0         14.5                    0.3      0.5   \n",
       "3         -73.954994    0.0         11.5                    0.3      0.5   \n",
       "\n",
       "       ...       payment_type  pickup_latitude  pickup_longitude  \\\n",
       "0      ...                  1        40.778149        -73.956291   \n",
       "1      ...                  2        40.729458        -73.983864   \n",
       "2      ...                  2        40.743740        -73.987617   \n",
       "3      ...                  2        40.757507        -73.981682   \n",
       "\n",
       "   store_and_fwd_flag tip_amount  tolls_amount  total_amount  \\\n",
       "0                   N        2.1             0          12.4   \n",
       "1                   N        0.0             0          14.8   \n",
       "2                   N        0.0             0          15.3   \n",
       "3                   N        0.0             0          12.3   \n",
       "\n",
       "       tpep_dropoff_datetime       tpep_pickup_datetime trip_distance  \n",
       "0 1970-01-01 00:23:42.268943 1970-01-01 00:23:42.268218          1.76  \n",
       "1 1970-01-01 00:23:42.137577 1970-01-01 00:23:42.136892          3.73  \n",
       "2 1970-01-01 00:23:42.719906 1970-01-01 00:23:42.718711          2.84  \n",
       "3 1970-01-01 00:23:40.907558 1970-01-01 00:23:40.906601          2.18  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_feature_layer = subset_item.layers[0]\n",
    "\n",
    "# query the attribute information. Limit to first 5 rows.\n",
    "query_result = subset_feature_layer.query(where = 'OBJECTID < 5',\n",
    "                                          out_fields = \"*\", \n",
    "                                          returnGeometry = False)\n",
    "\n",
    "att_data_frame = query_result.sdf # get as a Pandas dataframe\n",
    "att_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above represents the attribute information available from the NYC dataset. Columns provide a wealth of infomation such as pickup and dropoff_locations, fares, tips, tolls, and trip distances which you can analyze to observe many interesting patterns. The full data dataset contains over 24 million points. To discern patterns out of it, let us aggregate the points into blocks of 1 square kilometer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for big data file shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process data using GeoAnalytics Server, you need to have registered the data with your Geoanalytics Server. In this sample the data is in multiple csv files, which have been previously registered as a big data file share.\n",
    "\n",
    "Let us connect to an ArcGIS Enterprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(\"https://pythonapi.playground.esri.com/portal\", \"arcgis_python\", \"amazing_arcgis_123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the Geoanalytics [is supported](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.toc.html#arcgis.geoanalytics.is_supported) with our GIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcgis.geoanalytics.is_supported()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the geoanalytics datastores and search it for the registered datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastores = arcgis.geoanalytics.get_datastores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Datastore title:\"/bigDataFileShares/NYC_taxi_data15\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/all_hurricanes\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_1848_1900\" type:\"bigDataFileShare\">]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata_fileshares = datastores.search()\n",
    "bigdata_fileshares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NYC_taxi_data15 is registered as a `big data file share` with the Geoanalytics datastore, so we can reference it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = bigdata_fileshares[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering big data file shares\n",
    "\n",
    "The code below shows how a big data file share can be registered with the geoanalytics datastores, in case it's not already registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Data file share exists for NYCdata\n"
     ]
    }
   ],
   "source": [
    "data_item = datastores.add_bigdata(\"NYCdata\", r\"\\\\pathway\\to\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a big data file share is created, the GeoAnalytics server processes all the valid file types to discern the schema of the data. This process can take a few minutes depending on the size of your data. Once processed, querying the [`manifest`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html?highlight=manifest#arcgis.gis.Datastore.manifest) property returns the schema. As you can see from below, the schema is similar to the subset we observed earlier in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': '2015',\n",
       "   'format': {'quoteChar': '\"',\n",
       "    'fieldDelimiter': ',',\n",
       "    'hasHeaderRow': True,\n",
       "    'encoding': 'UTF-8',\n",
       "    'recordTerminator': '\\n',\n",
       "    'type': 'delimited',\n",
       "    'extension': 'csv'},\n",
       "   'schema': {'fields': [{'name': 'VendorID',\n",
       "      'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'tpep_pickup_datetime', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'tpep_dropoff_datetime', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'passenger_count', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'trip_distance', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'pickup_longitude', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'pickup_latitude', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'RateCodeID', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'store_and_fwd_flag', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'dropoff_longitude', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'dropoff_latitude', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'payment_type', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'fare_amount', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'extra', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'mta_tax', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'tip_amount', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'tolls_amount', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'improvement_surcharge', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'total_amount', 'type': 'esriFieldTypeDouble'}]},\n",
       "   'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "    'spatialReference': {'wkid': 4326},\n",
       "    'fields': [{'name': 'pickup_longitude', 'formats': ['x']},\n",
       "     {'name': 'pickup_latitude', 'formats': ['y']}]},\n",
       "   'time': {'timeType': 'instant',\n",
       "    'timeReference': {'timeZone': 'UTC'},\n",
       "    'fields': [{'name': 'tpep_pickup_datetime',\n",
       "      'formats': ['yyyy-MM-dd HH:mm:ss']}]}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item.manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you add a big data file share datastore, a corresponding item gets created on your portal. You can search for it like a regular item and query its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"bigDataFileShares_all_hurricanes\" type:Big Data File Share owner:api_data_owner>,\n",
       " <Item title:\"bigDataFileShares_hurricanes_1848_1900\" type:Big Data File Share owner:arcgis_python>,\n",
       " <Item title:\"bigDataFileShares_NYC_taxi_data15\" type:Big Data File Share owner:api_data_owner>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = gis.content.search(\"\", item_type = \"big data file share\")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://pythonapi.playground.esri.com/portal/home/item.html?id=a2fed6f0de474fe4a6bb7176e9c9b204' target='_blank'>\n",
       "                        <img src='https://pythonapi.playground.esri.com/portal/portalimages/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://pythonapi.playground.esri.com/portal/home/item.html?id=a2fed6f0de474fe4a6bb7176e9c9b204' target='_blank'><b>bigDataFileShares_NYC_taxi_data15</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://pythonapi.playground.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/layers16.png' style=\"vertical-align:middle;\">Big Data File Share by api_data_owner\n",
       "                        <br/>Last Modified: May 01, 2018\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"bigDataFileShares_NYC_taxi_data15\" type:Big Data File Share owner:api_data_owner>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item = search_result[2]\n",
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Layer url:\"https://pythonapi.playground.esri.com/ga/rest/services/DataStoreCatalogs/bigDataFileShares_NYC_taxi_data15/BigDataCatalogServer/2015\">]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Layer url:\"https://pythonapi.playground.esri.com/ga/rest/services/DataStoreCatalogs/bigDataFileShares_NYC_taxi_data15/BigDataCatalogServer/2015\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_2015 = data_item.layers[0]\n",
    "year_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate points tool\n",
    "You access the [`aggregate_points()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.summarize_data.html#aggregate-points) tool in the [`summarize_data`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.summarize_data.html#) submodule of the [`geoanalytics`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.toc.html) module. In this example, we are using this tool to aggregate the numerous points into 1 kilometer square blocks. The tool creates a polygon feature layer in which each polygon contains aggregated attribute information from all the points in the input dataset that fall within that polygon. The output feature layer contains only polygons that contain at least one point from the input dataset. See [Aggregate Points](http://enterprise.arcgis.com/en/server/latest/get-started/windows/geoanalyticstool-aggregatepoints.htm) for details on using this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.geoanalytics.summarize_data import aggregate_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregate points tool requires that either:\n",
    "  * the point layer is projected, or\n",
    "  * the output or processing coordinate system is set to a Projected Coordinate System\n",
    "\n",
    "We can query the layer `properties` to investigate the coordinate system of the point layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wkid': 4326}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_2015.properties['spatialReference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since WGS84 (the coordinate system referred to by wkid 4326) is unprojected, we can use the [`arcgis.env`]() module to set the environment used in the tool processing. The [`process_spatial_reference`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.env.html#arcgis.env.process_spatial_reference) environment setting controls the geometry processing of tools used by the API for Python. We can set this parameter to a projected coordinate system for tool processing:\n",
    "\n",
    "> **NOTE:** The ouput layer for GeoAnalytics Tools always gets stored in the WGS84 Spatial Reference. See the `Usage notes` section of the [`help`](http://enterprise.arcgis.com/en/server/latest/get-started/windows/geoanalyticstool-aggregatepoints.htm) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcgis.env.process_spatial_reference=3857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [`arcgis.env`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.env.html) module to modify environment settings that geoprocessing and geoanalytics tools use during execution. Set [`verbose`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.env.html#verbose) to `True` to return detailed messaging when running tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcgis.env.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the tool, specifying 1 kilometer squares as the polygons for which we want to aggregate information about all the NYC taxi information in each of those polygons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted.\n",
      "Executing...\n",
      "Executing (AggregatePoints): AggregatePoints \"Feature Set\" Square 1 Kilometers # # # # # # # \"{\"serviceProperties\": {\"name\": \"Aggregate_Points_Analysis_PAMJHK\", \"serviceUrl\": \"https://pythonapi.playground.esri.com/server/rest/services/Hosted/Aggregate_Points_Analysis_PAMJHK/FeatureServer\"}, \"itemProperties\": {\"itemId\": \"5cf0d7a3676f496fbcb9f9d460242583\"}}\" \"{\"processSR\": {\"wkid\": 3857}}\"\n",
      "Start Time: Thu May 24 17:16:38 2018\n",
      "Using URL based GPRecordSet param: https://pythonapi.playground.esri.com/ga/rest/services/DataStoreCatalogs/bigDataFileShares_NYC_taxi_data15/BigDataCatalogServer/2015\n",
      "{\"messageCode\":\"BD_101033\",\"message\":\"'pointLayer' will be projected into the processing spatial reference.\",\"params\":{\"paramName\":\"pointLayer\"}}\n",
      "{\"messageCode\":\"BD_101028\",\"message\":\"Starting new distributed job with 236 tasks.\",\"params\":{\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"0/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"0\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"1/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"1\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"9/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"9\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"17/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"17\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"25/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"25\",\"totalTasks\":\"236\"}}\n",
      "                                    .\n",
      "                                    .\n",
      "                                    .\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"123/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"123\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"222/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"222\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101029\",\"message\":\"236/236 distributed tasks completed.\",\"params\":{\"completedTasks\":\"236\",\"totalTasks\":\"236\"}}\n",
      "{\"messageCode\":\"BD_101081\",\"message\":\"Finished writing results:\"}\n",
      "{\"messageCode\":\"BD_101082\",\"message\":\"* Count of features = 4560\",\"params\":{\"resultCount\":\"4560\"}}\n",
      "{\"messageCode\":\"BD_101083\",\"message\":\"* Spatial extent = {\\\"xmin\\\":-140.5863419647051,\\\"ymin\\\":-27.777893572271292,\\\"xmax\\\":78.66546943034649,\\\"ymax\\\":82.49801821869467}\",\"params\":{\"extent\":\"{\\\"xmin\\\":-140.5863419647051,\\\"ymin\\\":-27.777893572271292,\\\"xmax\\\":78.66546943034649,\\\"ymax\\\":82.49801821869467}\"}}\n",
      "{\"messageCode\":\"BD_101084\",\"message\":\"* Temporal extent = None\",\"params\":{\"extent\":\"None\"}}\n",
      "{\"messageCode\":\"BD_0\",\"message\":\"Feature service layer created: https://pythonapi.playground.esri.com/server/rest/services/Hosted/Aggregate_Points_Analysis_PAMJHK/FeatureServer/0\",\"params\":{\"serviceUrl\":\"https://pythonapi.playground.esri.com/server/rest/services/Hosted/Aggregate_Points_Analysis_PAMJHK/FeatureServer/0\"}}\n",
      "Succeeded at Thu May 24 17:18:29 2018 (Elapsed Time: 1 minutes 50 seconds)\n"
     ]
    }
   ],
   "source": [
    "agg_result = aggregate_points(year_2015, \n",
    "                              bin_type = 'square',\n",
    "                              bin_size=1, \n",
    "                              bin_size_unit='Kilometers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inspect the results\n",
    "\n",
    "Let us create a map and load the processed result which is a feature layer item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_map = gis.map('New York, NY', 11)\n",
    "processed_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nyc_processed_img](http://esri.github.io/arcgis-python-api/notebooks/nbimages/04_AnalyzingNYCtaxi_02.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_map.add_layer(agg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the item we just created is not shared, so additinal processing requires login credentials. Let's [`share()`] the item to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'notSharedWith': [], 'itemId': '5cf0d7a3676f496fbcb9f9d460242583'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_result.share(org=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the analysis result using smart mapping. To learn more about this visualization capability, refer to the guide on [Smart Mapping](https://developers.arcgis.com/python/guide/smart-mapping/) under the 'Mapping and Visualization' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = gis.map(\"New York, NY\", 11)\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nyc_renderer_img](http://esri.github.io/arcgis-python-api/notebooks/nbimages/04_AnalyzingNYCtaxi_03.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2.add_layer(agg_result, {\n",
    "                \"renderer\":\"ClassedColorRenderer\",\n",
    "                \"field_name\":\"MAX_tip_amount\", \n",
    "                \"normalizationField\":'MAX_trip_distance',\n",
    "                \"classificationMethod\":'natural-breaks',\n",
    "                \"opacity\":0.75\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start seeing patterns, such as which pickup areas resulted in higher tips for the cab drivers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
