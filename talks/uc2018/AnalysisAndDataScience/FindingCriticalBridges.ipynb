{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Act2_Pic01_Short.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Act2_Pic02_Alt.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import arcgis\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gis = arcgis.gis.GIS(url=\"https://ndirt.maps.arcgis.com\", username=\"ANieto_ndirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bridge_item = gis.content.search(\"DCVAMD_NBI_Bridges\", item_type=\"feature service\")[0]\n",
    "bridge_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deficient_bridge_item = gis.content.search(\"DCVAMD_CBSA_DeficientBridges\", item_type=\"feature service\")[0]\n",
    "deficient_bridge_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analyzed_bridges_item = gis.content.search(\"Bridges_Analyzed\", item_type=\"feature service\")[0]\n",
    "analyzed_bridges_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analyzed_bridges_lyr = analyzed_bridges_item.layers[0]\n",
    "analyzed_bridges_lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analyzed_bridges_item.layers[0].query(\"1=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzed_bridges_top_ranked = analyzed_bridges_item.layers[0].query(\"cbsa_rank = 1\")\n",
    "analyzed_bridges_top_ranked_df = analyzed_bridges_top_ranked.df\n",
    "analyzed_bridges_top_ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "commute_df = pd.DataFrame.from_csv(r\"D:\\5_Data\\Transportation\\Transit\\commute_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tract_polys = gis.content.search(\"DCVAMD_CBSA_Tracts_Polygons\", item_type=\"feature service\")[0]\n",
    "tract_points = gis.content.search(\"DCVAMD_CBSA_Tracts_Centroids\", item_type=\"feature service\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tract_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tract_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "route_items = gis.content.search(\"Test Routes\", item_type=\"feature service\")\n",
    "origin_dest_points = route_items[0]\n",
    "normal_route = route_items[2]\n",
    "impaired_route = route_items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normal_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "impaired_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def animate_layer_addition_to_map(map_widget, list_of_items, zoom_level, basemap='gray-vector'):\n",
    "    # The map widget\n",
    "    m = map_widget\n",
    "    m.basemap = basemap\n",
    "    \n",
    "    # 1. Parse the find-routes analysis results\n",
    "    # Extract the output data from the analysis results\n",
    "    # Store the output points and lines in pandas dataframes\n",
    "    lines_df = result.output_routes.df\n",
    "    lines_fset = arcgis.features.FeatureSet.from_dataframe(lines_df)\n",
    "    \n",
    "    # 2. Define the map symbology\n",
    "    # Allocation lines\n",
    "    allocation_line_symbol_1 = {'type': 'esriSLS', 'style': 'esriSLSSolid',\n",
    "                                'color': [255,255,255,153], 'width': 0.7}\n",
    "\n",
    "    allocation_line_symbol_2 = {'type': 'esriSLS', 'style': 'esriSLSSolid',\n",
    "                                'color': [0,255,197,39], 'width': 3}\n",
    "\n",
    "    allocation_line_symbol_3 = {'type': 'esriSLS', 'style': 'esriSLSSolid',\n",
    "                                'color': [0,197,255,39], 'width': 5}\n",
    "    \n",
    "    allocation_line_symbol_4 = {'type': 'esriSLS', 'style': 'esriSLSSolid',\n",
    "                                'color': [0,92,230,39], 'width': 7}\n",
    "    \n",
    "    time.sleep(1.5)\n",
    "    m.draw(shape=result.output_routes, symbol=allocation_line_symbol_4)\n",
    "    m.draw(shape=result.output_routes, symbol=allocation_line_symbol_2)\n",
    "    m.draw(shape=result.output_routes, symbol=allocation_line_symbol_1)\n",
    "    \n",
    "    m.add_layer(stops_layer)\n",
    "    \n",
    "    m.zoom = zoom_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Analysis Methodology\n",
    "\n",
    "### 1. Ask questions: \n",
    "Formulate hypotheses and spatial\n",
    "questions.\n",
    "\n",
    "### 2. Explore the data: \n",
    "Examine the data quality,\n",
    "completeness, and measurement limitations (scale\n",
    "and resolution) to determine the level of analysis and\n",
    "interpretation that can be supported.\n",
    "\n",
    "### 3. Analyze and model: \n",
    "Break the problem down into\n",
    "solvable components that can be modeled. Quantify\n",
    "and evaluate the spatial questions.\n",
    "\n",
    "### 4. Interpret the results: \n",
    "Evaluate and analyze the results\n",
    "in the context of the question posed, data limitations,\n",
    "accuracy, and other implications.\n",
    "\n",
    "### 5. Repeat as necessary: \n",
    "Spatial analysis is a continuous\n",
    "and iterative process that often leads to further\n",
    "questions and refinements.\n",
    "\n",
    "### 6. Present the results: \n",
    "The best information and\n",
    "analysis becomes increasingly valuable when it can be\n",
    "effectively presented and shared with a larger audience.\n",
    "\n",
    "### 7. Make a decision: \n",
    "\n",
    "Spatial analysis and GIS are used to support the \n",
    "decision-making process. A successful spatial analysis \n",
    "process often leads to the understanding necessary to \n",
    "drive decisions and action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. Ask Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## What would be the impact to commuters if a structurally deficient bridge is impaired?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Exploring Bridge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Bridges in the DC Area (CBSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bridges_map = gis.map('Fairfax County', zoomlevel=8)\n",
    "bridges_map.basemap = 'gray-vector'\n",
    "display(bridges_map)\n",
    "bridges_map.add_layer(bridge_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bridges_sdf = arcgis.features.SpatialDataFrame.from_layer(bridge_item.layers[0]); bridges_sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print([col for col in bridges_sdf.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "National Bridge Inventory (NBI) Schema: https://www.fhwa.dot.gov/bridge/mtguide.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Structurally Deficient Bridges in the DC Area (CBSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "deficient_bridges_map = gis.map('Fairfax County', zoomlevel=8)\n",
    "deficient_bridges_map.basemap = 'gray-vector'\n",
    "display(deficient_bridges_map)\n",
    "deficient_bridges_map.add_layer(deficient_bridge_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Exploring Commuting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Map of all DC CBSA Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tracts_map = gis.map('Arlington, VA', zoomlevel=9)\n",
    "tracts_map.basemap = 'streets-night-vector'\n",
    "tracts_map.add_layer(tract_points)\n",
    "display(tracts_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Table of Commuting Patterns by Tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Census Journey to Work Data: https://www.census.gov/topics/employment/commuting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "commute_df = pd.DataFrame.from_csv(r\"D:\\5_Data\\Transportation\\Transit\\commute_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "commute_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Analyze and model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Analysis Question: What would be the impact to commuters if a structurally deficient bridge is impaired?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploration_map = gis.map('Arlington, VA', zoomlevel=9)\n",
    "exploration_map.basemap = 'streets-night-vector'\n",
    "exploration_map.add_layer(tract_points)\n",
    "display(exploration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploration_map.add_layer(deficient_bridge_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Let's explore an example commute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2 = gis.map('Washington Navy Yard', zoomlevel=12)\n",
    "m2.basemap = 'gray-vector'\n",
    "display(m2)\n",
    "m2.add_layer(origin_dest_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2.add_layer(normal_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2.add_layer(deficient_bridge_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2.add_layer(impaired_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Prototype Analysis Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"img/Analysis_Process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"img/odmc_restriction_01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Automated Workflow Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. Set Environment and Retrieve Bridge and Commute Pattern Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "processing_workspace = r\"D:\\ANieto_SolutionEngineer\\Projects\\FedGIS\\ArcGISAPIforPython_Workspace\\bridge_processing\"\n",
    "workspace_gdb = r\"D:\\ANieto_SolutionEngineer\\Projects\\FedGIS\\ArcGISAPIforPython_Workspace\\BridgeCriticality_Arcpy_Workspace.gdb\"\n",
    "# workspace_gdb = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\BridgeCriticality_Arcpy_Workspace.gdb\"\n",
    "\n",
    "# Set Arcpy environment\n",
    "arcpy.env.workspace = workspace_gdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Set reference to origins\n",
    "origin_tracts = r\"D:\\ANieto_SolutionEngineer\\Projects\\FedGIS\\ArcGISAPIforPython_Workspace\\BridgeCriticality_Arcpy_Workspace.gdb\\DCVAMD_CBSA_Tracts_Centroids\"\n",
    "# origin_tracts = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\Bridge_Criticality_Analysis.gdb\\\\DCVAMD_CBSA_Tracts_Centroids\"\n",
    "origins_id_field = \"ID\"\n",
    "origins_name_field = \"NAME\"\n",
    "\n",
    "# Set reference to destinations\n",
    "dest_tracts = r\"D:\\ANieto_SolutionEngineer\\Projects\\FedGIS\\ArcGISAPIforPython_Workspace\\BridgeCriticality_Arcpy_Workspace.gdb\\DCVAMD_CBSA_Tracts_Centroids\"\n",
    "# dest_tracts = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\Bridge_Criticality_Analysis.gdb\\\\DCVAMD_CBSA_Tracts_Centroids\"\n",
    "dest_id_field = \"ID\"\n",
    "dest_name_field = \"NAME\"\n",
    "\n",
    "# Set reference to bridges\n",
    "bridges_fc = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\Bridge_Criticality_Analysis.gdb\\\\DCVAMD_CBSA_DeficientBridges\"\n",
    "polybarrier_bridges_fc = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\Bridge_Criticality_Analysis.gdb\\\\DCVAMD_CBSA_DeficientBridges_Polybarriers\"\n",
    "polybarriers_id_field = \"OBJECTID\"\n",
    "\n",
    "# Set reference to the network dataset\n",
    "network_dataset = \"C:\\\\ArcGIS\\\\Business Analyst\\\\US_2015\\\\Data\\\\Streets Data\\\\NAVTEQ_2014_Q3_NA.gdb\\\\Routing\\\\Routing_ND\"\n",
    "\n",
    "# Set reference to commute table\n",
    "commute_table = \"C:\\\\Users\\\\albe9057\\\\Documents\\\\ANieto_SolutionEngineering\\\\Projects\\\\FedGIS\\\\FedGIS_2018\\\\Plenary_ArcGISAPIforPython\\\\Work\\\\Bridge_Criticality_Analysis\\\\Bridge_Criticality_Analysis.gdb\\\\ctpp_journey_to_work\"\n",
    "\n",
    "# Set reference to impedance values needed for odcm\n",
    "impedance_value=99999\n",
    "impedance_attribute=\"Minutes\"\n",
    "accumulate_attributes = [\"Minutes\", \"Miles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. Perform Bridge Commuting Impacts Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Option 1: Python API ODCM via WebGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcgis.network.analysis.generate_origin_destination_cost_matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Option 2: Custom ODCM via ArcPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Custom ODCM Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_odcm(gdb,\n",
    "                origins_fc,\n",
    "                origins_id_field,\n",
    "                origins_name_field,\n",
    "                destinations_fc,\n",
    "                destinations_id_field,\n",
    "                destinations_name_field,\n",
    "                odcm_name,\n",
    "                network_dataset,\n",
    "                impedance_value,\n",
    "                impedance_attribute,\n",
    "                impedance_attribute_field_name=\"Dij\",\n",
    "                use_lines=False,\n",
    "                out_na_layer_name=\"Origins2Destinations\",\n",
    "                validate_inputs=False,\n",
    "                method_message=\"\\t\\tcreate_odcm: \",\n",
    "                output_origin_id_field_name='origin_id',\n",
    "                output_origin_name_field_name='origin_name',\n",
    "                output_dest_id_field_name='destination_id',\n",
    "                output_dest_name_field_name='destination_name',\n",
    "                logger_object=None):\n",
    "    \"\"\"\n",
    "    create_odcm: Creates an origin-destination cost matrix with additional output handling\n",
    "    \"\"\"\n",
    "\n",
    "    # Set standardized method messaging title\n",
    "\n",
    "    general_utils.log_print(\"{0}Initializing Origin-Destination Cost Matrix process...\".format(method_message),\n",
    "                            \"INFO\",\n",
    "                            logger_object)\n",
    "\n",
    "    # Establish workspace parameters\n",
    "    workspace = gdb\n",
    "    arcpy.env.workspace = workspace\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    # Determine which version of arcgis desktop is being used\n",
    "    DesktopVersion = ArcGISVersionChecker()[2]\n",
    "\n",
    "    lines_param = \"STRAIGHT_LINES\" if use_lines else \"NO_LINES\"\n",
    "    general_utils.log_print(\"DEVNOTE: lines_param={0}\".format(lines_param), \"DEBUG\", logger_object)\n",
    "\n",
    "    general_utils.log_print(\"{0}Acquiring Network Analyst extension...\".format(method_message), \"DEBUG\", logger_object)\n",
    "    # Acquire Network Analyst extension\n",
    "    if arcpy.CheckExtension(\"Network\") != \"Available\":\n",
    "        # Raise a custom exception\n",
    "        ##            raise LicenseError\n",
    "        general_utils.log_print(\"{0}ERROR: A Network Analyst License is required in order to create the ODCM; the ODCM will not be produced. Please consult with the GIS Developer if a license is expected to be available...\".format(method_message),\n",
    "                                \"ERROR\",\n",
    "                                logger_object)\n",
    "        raise ValueError(\"Unable to acquire a network analyst license!\")\n",
    "\n",
    "    elif arcpy.CheckExtension(\"Network\") == \"Available\":\n",
    "        arcpy.CheckOutExtension(\"Network\")\n",
    "\n",
    "        if validate_inputs:\n",
    "            # Perform verification of origins and destinations feature classes\n",
    "            general_utils.log_print(\"{0}Acquiring Origins...\".format(method_message), \"DEBUG\", logger_object)\n",
    "            if arcpy.Exists(origins_fc):\n",
    "                pass\n",
    "            else:\n",
    "                general_utils.log_print(\"Unable to run create_odcm with provided origins!\", \"ERROR\", logger_object)\n",
    "                raise ValueError(\"Unable to run create_odcm with provided origins!\")\n",
    "            print(\"{0}Acquiring Destinations...\".format(method_message))\n",
    "            if arcpy.Exists(destinations_fc):\n",
    "                pass\n",
    "            else:\n",
    "                general_utils.log_print(\"Unable to run create_odcm with provided destinations!\", \"ERROR\", logger_object)\n",
    "                raise ValueError(\"Unable to run create_odcm with provided destinations!\")\n",
    "\n",
    "        general_utils.log_print(\"{0}Establishing Network Analyst Layer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        outlayerfile = out_na_layer_name + \".lyr\"\n",
    "\n",
    "        general_utils.log_print(\"{0}The established impedance attribute is: {1}\".format(method_message, str(impedance_attribute)), \"DEBUG\", logger_object)\n",
    "        # Create variable that refers to the Impedance Attribute Field from the default ODCM Table\n",
    "        impedance_attribute_field = \"Total_\" + impedance_attribute\n",
    "\n",
    "        general_utils.log_print(\"{0}Establishing Destination Search Distance Cut-Off...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        # Import user parameter 'Impedance Cutoff'\n",
    "\n",
    "        general_utils.log_print(\"{0}Impedance Cutoff: {1}\".format(method_message, str(impedance_value)), \"DEBUG\", logger_object)\n",
    "        # Create the Composite Origin-Destination Cost Matrix Network Analysis Layer.\n",
    "\n",
    "        general_utils.log_print(\"{0}Creating Origin-Destination Cost Matrix...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        out_na_layer = arcpy.MakeODCostMatrixLayer_na(network_dataset,\n",
    "                                                      out_na_layer_name,\n",
    "                                                      impedance_attribute,\n",
    "                                                      impedance_value, \"\", \"\", \"\", \"\",\n",
    "                                                      \"USE_HIERARCHY\", \"\",\n",
    "                                                      lines_param).getOutput(0)\n",
    "\n",
    "        # Acquire the SubLayers from the Composite Origin-Destination Cost Matrix Network Analysis Layer\n",
    "        general_utils.log_print(\"{0}Acquiring Composite Network Analysis SubLayers...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        sublayer_names = arcpy.na.GetNAClassNames(out_na_layer)\n",
    "        # Acquire the Origin's SubLayer\n",
    "        general_utils.log_print(\"{0}Acquiring Origins SubLayer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        origins_layername = sublayer_names[\"Origins\"]\n",
    "        # Create a Field Map object to Map the 'CovLogic_Centroid' IDs to the Origins field of the Origin-Destination Cost Matrix\n",
    "        origins_fieldmap = arcpy.na.NAClassFieldMappings(out_na_layer, origins_layername)\n",
    "        origins_fieldmap[\"Name\"].mappedFieldName = origins_id_field\n",
    "        # Load the Origins into the Composite Network Analysis Layer.\n",
    "        general_utils.log_print(\"{0}Loading Origins into Composite Network Analysis Layer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.na.AddLocations(out_na_layer, origins_layername, origins_fc, origins_fieldmap)\n",
    "        # Acquire the Destinations SubLayer.\n",
    "        general_utils.log_print(\"{0}Acquiring Destinations SubLayer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        destinations_layername = sublayer_names[\"Destinations\"]\n",
    "        # Create a Field Map object to map the 'proForma' DIDs to the Destinations field of the Origin-Destination Cost Matrix.\n",
    "        destinations_fieldmap = arcpy.na.NAClassFieldMappings(out_na_layer, destinations_layername)\n",
    "        destinations_fieldmap[\"Name\"].mappedFieldName = destinations_id_field\n",
    "        # Load the Destinations into the Composite Network Analysis Layer.\n",
    "        general_utils.log_print(\"{0}Loading Destinations into Composite Network Analysis Layer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.na.AddLocations(out_na_layer, destinations_layername, destinations_fc, destinations_fieldmap)\n",
    "        # Solve the Network\n",
    "        general_utils.log_print(\"{0}Solving Network 'Origins2Destinations' Origin-Destination Cost Matrix...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.na.Solve(out_na_layer)\n",
    "        # Verify if the directory, C:\\Temp exists on the client system\n",
    "        if not os.path.exists(r\"C:\\Temp\"):\n",
    "            # IF the directory, C:\\Temp does not exist, create it\n",
    "            os.makedirs(r\"C:\\Temp\")\n",
    "        # Set the Workspace to C:\\Temp\n",
    "        general_utils.log_print(\"{0}Resetting Workspace to C:\\Temp...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.env.workspace = r\"C:\\Temp\"\n",
    "        # Extract the 'in_memory' result layer and save it as a Layer File in the workspace.\n",
    "        general_utils.log_print(\"{0}Extracting Result Layer from memory...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.SaveToLayerFile_management(out_na_layer, outlayerfile, \"RELATIVE\")\n",
    "        # Establish a reference to the Result Layer\n",
    "        general_utils.log_print(\"{0}Acquiring Result Layer...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        ResultLayer = arcpy.mapping.Layer(r\"C:\\Temp\\{0}.lyr\".format(out_na_layer_name))\n",
    "        # Reset the Workspace to the workspace\n",
    "        general_utils.log_print(\"{0}Resetting Workspace to {1}...\".format(method_message, str(workspace)), \"DEBUG\", logger_object)\n",
    "        arcpy.env.workspace = workspace\n",
    "        # Establish a reference to a standard ESRI Map Template\n",
    "        general_utils.log_print(\"{0}Acquiring ESRI Template MXD...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        TempMXD = arcpy.mapping.MapDocument(r\"C:\\Program Files (x86)\\ArcGIS\\\\{0}\\\\MapTemplates\\Traditional Layouts\\LetterPortrait.mxd\".format(str(DesktopVersion)))\n",
    "        # Establish a reference to the DataFrame within the ESRI Map Template\n",
    "        general_utils.log_print(\"{0}Acquiring ESRI Template MXD DataFrame...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        TempDF = arcpy.mapping.ListDataFrames(TempMXD)[0]\n",
    "        # Add the 'ResultLayer' to the DataFrame in the 'TempMXD'\n",
    "        general_utils.log_print(\"{0}Adding Result Layer to ESRI Template MXD...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.mapping.AddLayer(TempDF, ResultLayer)\n",
    "        # Create a container and dynamically populate it with the layer in the Dataframe named 'Lines'\n",
    "        lines_lyr = arcpy.mapping.ListLayers(TempMXD, \"Lines\", TempDF)\n",
    "        if len(lines_lyr) > 1:\n",
    "            raise ValueError(\"Multiple OD Cost Matrices populated in Template MXD. Cannot identify correct OD Cost Matrix.\")\n",
    "        elif len(lines_lyr) < 1:\n",
    "            raise ValueError(\"OD Cost Matrix was not populated in Template MXD. Unable to extract result.\")\n",
    "        else:\n",
    "            for lyr in lines_lyr:\n",
    "                # Export the table associated with the 'Lines' layer to a new table in the Workspace\n",
    "                general_utils.log_print(\"{0}Extracting Retail Node Sites Origin-Destination Cost Matrix...\".format(method_message), \"DEBUG\", logger_object)\n",
    "                arcpy.TableToTable_conversion(lyr, workspace, \"ODCM_{0}\".format(str(odcm_name)))\n",
    "                # Remove the layer from the TempMXD's DataFrame\n",
    "                general_utils.log_print(\"{0}Removing Result Layer from ESRI Template MXD...\".format(method_message), \"DEBUG\", logger_object)\n",
    "                arcpy.mapping.RemoveLayer(TempDF, lyr)\n",
    "                # Delete the 'ResultLayer' file from disk\n",
    "                if not use_lines:\n",
    "                    general_utils.log_print(\"{0}Deleting Result Layer from disk...\".format(method_message), \"DEBUG\", logger_object)\n",
    "                    arcpy.Delete_management(r\"C:\\Temp\\{0}.lyr\".format(out_na_layer_name))\n",
    "        # Establish a reference to the ProForma Sites Origin-Destination Cost Matrix\n",
    "        general_utils.log_print(\"{0}Acquiring Origin-Destination Cost Matrix...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        odcm = \"{0}\\\\ODCM_{1}\".format(workspace, str(odcm_name))\n",
    "        # Display a message to the user that the Origin-Destination Cost Matrix generation process completed\n",
    "        general_utils.log_print(\"{0}Origin-Destination Cost Matrix data loading process complete.\".format(method_message), \"DEBUG\", logger_object)\n",
    "\n",
    "        \"\"\" [SP] Hydrate Origin-Destination Cost Matrix\"\"\"\n",
    "        # Delete any unnecessary fields ('DestinationID', 'OriginID', 'DestinationRank') from the current odcm\n",
    "        general_utils.log_print(\n",
    "            \"{0}Performing ODCM preparation and preliminary calculations...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        general_utils.log_print(\n",
    "            \"{0}Deleting fields 'DestinationID' | 'OriginID' from ODCM...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.DeleteField_management(odcm, [\"DestinationID\", \"OriginID\"])\n",
    "\n",
    "        # Create a new fields for origin and destinations in the 'ODCM' table\n",
    "\n",
    "        # Add id field for origin ids\n",
    "        general_utils.log_print(\"{0}Creating new field '{1}'...\".format(method_message, output_origin_id_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.AddField_management(odcm, output_origin_id_field_name, \"TEXT\", \"\", \"\", 20, output_origin_id_field_name,\n",
    "                                  \"NULLABLE\",\n",
    "                                  \"REQUIRED\")\n",
    "        # Add name field for origins\n",
    "        general_utils.log_print(\"{0}Creating new field '{1}'...\".format(method_message, output_origin_name_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.AddField_management(odcm, output_origin_name_field_name, \"TEXT\", \"\", \"\", 100,\n",
    "                                  output_origin_name_field_name,\n",
    "                                  \"NULLABLE\", \"REQUIRED\")\n",
    "\n",
    "        # Destinations fields\n",
    "        # Add id field for destinations\n",
    "        general_utils.log_print(\"{0}Creating new field '{1}'...\".format(method_message, output_dest_id_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.AddField_management(odcm, output_dest_id_field_name, \"TEXT\", \"\", \"\", 20,\n",
    "                                  output_dest_id_field_name,\n",
    "                                  \"NULLABLE\", \"REQUIRED\")\n",
    "        # Add name field for destinations\n",
    "        general_utils.log_print(\"{0}Creating new field '{1}'...\".format(method_message, output_dest_name_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.AddField_management(odcm, output_dest_name_field_name, \"TEXT\", \"\", \"\", 100,\n",
    "                                  output_dest_name_field_name,\n",
    "                                  \"NULLABLE\", \"REQUIRED\")\n",
    "\n",
    "        # Calculate the 'OriginID' and 'DestinationID' fields in the 'ODCM' table,\n",
    "        # populating the field with the components from the default 'Name' field in the odcm table\n",
    "        general_utils.log_print(\"{0}Calculating '{1}', '{2}' fields...\".format(method_message,\n",
    "                                                             output_origin_id_field_name,\n",
    "                                                             output_dest_id_field_name), \"DEBUG\", logger_object)\n",
    "        with arcpy.da.UpdateCursor(odcm, ['Name', output_origin_id_field_name, output_dest_id_field_name]) as cursor:\n",
    "            for row in cursor:\n",
    "                string = row[0]\n",
    "                origin_id = string.split(' - ')[0]\n",
    "                dest_id = string.split(' - ')[1]\n",
    "                row[1] = origin_id\n",
    "                row[2] = dest_id\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "        # Create a new field 'Dij' in the 'ODCM' table\n",
    "        general_utils.log_print(\"{0}Creating new field '{1}'...\".format(method_message, impedance_attribute_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.AddField_management(odcm,\n",
    "                                  impedance_attribute_field_name,\n",
    "                                  \"DOUBLE\", 15, 5, \"\",\n",
    "                                  impedance_attribute_field_name, \"NULLABLE\",\n",
    "                                  \"REQUIRED\")\n",
    "        # Calculate the 'Dij' field in the 'ODCM' table\n",
    "        general_utils.log_print(\"{0}Calculating '{1}' field...\".format(method_message, impedance_attribute_field_name), \"DEBUG\", logger_object)\n",
    "        arcpy.CalculateField_management(odcm,\n",
    "                                        impedance_attribute_field_name,\n",
    "                                        \"!\" + impedance_attribute_field + \"!\",\n",
    "                                        \"PYTHON\")\n",
    "        # Round the values held in the 'Dij' field in the 'ODCM' table to the nearest 5 significant digits\n",
    "        arcpy.CalculateField_management(odcm,\n",
    "                                        impedance_attribute_field_name,\n",
    "                                        \"round(!{0}!, 5)\".format(impedance_attribute_field_name),\n",
    "                                        \"PYTHON\")\n",
    "        # Delete the default impedence attribute field from the 'ODCM' table\n",
    "        general_utils.log_print(\"{0}Removing default impedance attribute field...\".format(method_message), \"DEBUG\", logger_object)\n",
    "        arcpy.DeleteField_management(odcm, str(impedance_attribute_field))\n",
    "\n",
    "        general_utils.log_print(\"{0}Operation complete. Go Gators.\".format(method_message), \"DEBUG\", logger_object)\n",
    "\n",
    "        arcpy.CheckInExtension(\"Network\")\n",
    "        return odcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Run ODCM for Nominal Commute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"nominal_odcm.csv\"):\n",
    "    print(\"Found nominal ODCM. Using processed data...\")\n",
    "    nominal_odcm_df = pd.DataFrame.from_csv(\"nominal_odcm.csv\")\n",
    "    \n",
    "else:\n",
    "\n",
    "    # Run nominal ODCM using tracts to tracts\n",
    "    nominal_odcm = create_odcm(gdb=workspace_gdb,\n",
    "                               origins_fc=origin_tracts,\n",
    "                               origins_id_field=origins_id_field,\n",
    "                               origins_name_field=origins_name_field,\n",
    "                               destinations_fc=dest_tracts,\n",
    "                               destinations_id_field=dest_id_field,\n",
    "                               destinations_name_field=dest_name_field,\n",
    "                               odcm_name=\"nominal_baseline\",\n",
    "                               network_dataset=network_dataset,\n",
    "                               impedance_value=impedance_value,\n",
    "                               impedance_attribute=impedance_attribute,\n",
    "                               accumulate_attribute_name=accumulate_attributes,\n",
    "                               polybarrier_fc=None,\n",
    "                               polybarrier_id_field=None,\n",
    "                               polybarrier_name_field=None,\n",
    "                               impedance_attribute_field_name=\"Dij\",\n",
    "                               use_lines=False,\n",
    "                               out_na_layer_name=\"Origins2Destinations\",\n",
    "                               validate_inputs=False,\n",
    "                               method_message=\"create_odcm: \",\n",
    "                               output_origin_id_field_name='origin_id',\n",
    "                               output_origin_name_field_name='origin_name',\n",
    "                               output_dest_id_field_name='destination_id',\n",
    "                               output_dest_name_field_name='destination_name',\n",
    "                               logger_object=None)\n",
    "\n",
    "    # Convert the odcm gis table to a pandas dataframe\n",
    "    print(\"Calculating ID Fields...\")\n",
    "    nominal_odcm_df = convert_gis_table_to_pddataframe(nominal_odcm)\n",
    "    nominal_odcm_df['OriginID'] = nominal_odcm_df.apply(lambda row: get_origin_id_from_odid(row['Name']), axis=1)\n",
    "    nominal_odcm_df['DestinationID'] = nominal_odcm_df.apply(lambda row: get_dest_id_from_odid(row['Name']), axis=1)\n",
    "    nominal_odcm_df.to_csv(\"nominal_odcm.csv\")\n",
    "\n",
    "nominal_odcm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Run Bridge Iteration: For each Bridge, Run ODCM with Bridge Feature as a Network Barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set iteration: Structurally Deficient Bridges in DC Metropolitan Region from NBI data\n",
    "\n",
    "# Build list of buffered bridges\n",
    "bridges_list = [row[0] for row in arcpy.da.SearchCursor(polybarrier_bridges_fc, polybarriers_id_field)]\n",
    "\n",
    "# Make bridges processing directory\n",
    "bridge_dir_path = r\"D:\\ANieto_SolutionEngineer\\Projects\\FedGIS\\ArcGISAPIforPython_Workspace\\bridge_processing\"\n",
    "\n",
    "if not os.path.isdir(bridge_dir_path):\n",
    "    os.mkdir(bridge_dir_path)\n",
    "    brigde_dir = bridge_dir_path\n",
    "else:\n",
    "    bridge_dir = bridge_dir_path\n",
    "\n",
    "os.chdir(bridge_dir)\n",
    "\n",
    "# For each bridge\n",
    "for bridge in bridges_list:\n",
    "    \n",
    "    print(\"\\nChecking bridge {0} of {1}...\".format(str(bridge), str(len(bridges_list))))\n",
    "    if os.path.isfile(\"impacted_commuters_odcm_{0}.csv\".format(str(bridge))):\n",
    "        print(\"Found bridge. Using processed data...\")\n",
    "        impacted_commuters_df = pd.DataFrame.from_csv(\"impacted_commuters_odcm_{0}.csv\".format(str(bridge)))\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"\\nProcessing bridge {0} of {1}...\".format(str(bridge), str(len(bridges_list))))\n",
    "        # Set where clause\n",
    "        bridge_sql = \"{0} = {1}\".format(arcpy.AddFieldDelimiters(polybarrier_bridges_fc, polybarriers_id_field), bridge)\n",
    "\n",
    "        # Export feature to act as a single polyline barrier\n",
    "        polybarrier_bridge_fc = arcpy.Select_analysis(polybarrier_bridges_fc, \"{0}/Bridge_{1}\".format(workspace_gdb, str(bridge)), bridge_sql)\n",
    "\n",
    "        # Run impaired ODCM using tracts to tracts, using a bridge feature as a polygon barrier\n",
    "        impaired_odcm = create_odcm(gdb=workspace_gdb,\n",
    "                                origins_fc=origin_tracts,\n",
    "                                origins_id_field=origins_id_field,\n",
    "                                origins_name_field=origins_name_field,\n",
    "                                destinations_fc=dest_tracts,\n",
    "                                destinations_id_field=dest_id_field,\n",
    "                                destinations_name_field=dest_name_field,\n",
    "                                odcm_name=\"impaired_test\",\n",
    "                                network_dataset=network_dataset,\n",
    "                                impedance_value=impedance_value,\n",
    "                                impedance_attribute=impedance_attribute,\n",
    "                                accumulate_attribute_name=accumulate_attributes,\n",
    "                                polybarrier_fc=polybarrier_bridge_fc,\n",
    "                                polybarrier_id_field=polybarriers_id_field,\n",
    "                                polybarrier_name_field=\"ITEM6A\",\n",
    "                                impedance_attribute_field_name=\"Dij\",\n",
    "                                use_lines=False,\n",
    "                                out_na_layer_name=\"Origins2Destinations\",\n",
    "                                validate_inputs=False,\n",
    "                                method_message=\"create_odcm: \",\n",
    "                                output_origin_id_field_name='origin_id',\n",
    "                                output_origin_name_field_name='origin_name',\n",
    "                                output_dest_id_field_name='destination_id',\n",
    "                                output_dest_name_field_name='destination_name',\n",
    "                                logger_object=None)\n",
    "\n",
    "        # Convert the odcm gis table to a pandas dataframe\n",
    "        impaired_odcm_csv = gis_table_to_csv(impaired_odcm, bridge_dir, \"impaired_odcm_{0}.csv\".format(str(bridge)))\n",
    "        impaired_odcm_df = pd.DataFrame.from_csv(impaired_odcm_csv)\n",
    "        \n",
    "#         impaired_odcm_df = convert_gis_table_to_pddataframe(impaired_odcm)\n",
    "        impaired_odcm_df['OriginID'] = impaired_odcm_df.apply(lambda row: get_origin_id_from_odid(row['Name']), axis=1)\n",
    "        impaired_odcm_df['DestinationID'] = impaired_odcm_df.apply(lambda row: get_dest_id_from_odid(row['Name']), axis=1)\n",
    "        impaired_odcm_df.to_csv(\"impaired_odcm_{0}.csv\".format(str(bridge)))\n",
    "\n",
    "        # Join nominal and impaired ODCM dataframes\n",
    "        nom_imp_odcm_df = pd.merge(nominal_odcm_df, impaired_odcm_df, how=\"left\", on=\"Name\")\n",
    "\n",
    "        # Join nominal+impaired ODCM dataframe to commute dataframe (inner join; remove anything not common)\n",
    "        commute_impacts_df = pd.merge(commute_df, nom_imp_odcm_df, how=\"inner\", left_on=\"ORIGIN_DESTINATION_ID\", right_on=\"Name\")\n",
    "        commute_impacts_df.to_csv(\"commute_impacts_odcm_{0}.csv\".format(str(bridge)))\n",
    "\n",
    "        # Identify deltas in impedance\n",
    "        commute_impacts_df['minutes_diff'] = commute_impacts_df['Total_Minutes_x'] - commute_impacts_df['Total_Minutes_y']\n",
    "        commute_impacts_df['miles_diff'] = commute_impacts_df['Total_Miles_x'] - commute_impacts_df['Total_Miles_y']\n",
    "        impacted_commuters_df = commute_impacts_df.loc[commute_impacts_df['minutes_diff'] > 0]\n",
    "        impacted_commuters_df.to_csv(\"impacted_commuters_odcm_{0}.csv\".format(str(bridge)))\n",
    "\n",
    "    # Calculate count and impedance sum in deltas\n",
    "    routes_impacted = impacted_commuters_df.shape[0]\n",
    "    commuters_impacted = commuters_impacted = impacted_commuters_df['EST'].sum()\n",
    "    total_additional_minutes = impacted_commuters_df['minutes_diff'].sum()\n",
    "    total_additional_miles = impacted_commuters_df['miles_diff'].sum()\n",
    "\n",
    "    bridges_df.loc[bridge, \"routes_impacted\"] = routes_impacted\n",
    "    bridges_df.loc[bridge, \"commuters_impacted\"] = commuters_impacted\n",
    "    bridges_df.loc[bridge, \"total_additional_minutes\"] = total_additional_minutes\n",
    "    bridges_df.loc[bridge, \"total_additional_miles\"] = total_additional_miles\n",
    "    \n",
    "    \n",
    "print(\"Complete.\")\n",
    "bridges_df.to_csv(r\"C:\\Users\\albe9057\\Documents\\GitHub\\ArcGISPythonAPI_Projects\\Presentation\\FedGIS2018\\bridges_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Calculate \"Impact Rank\" for bridges for entire study area (CBSA) and for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stack rank all bridges based on criticality score\n",
    "bridges_df['cbsa_rank'] = bridges_df['total_additional_miles'].rank(ascending=False); bridges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group-by for county rankings\n",
    "bridges_df['county_rank'] = bridges_df.groupby('ITEM3')['total_additional_miles'].rank(ascending=False); bridges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Publish Outputs to WebGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Publish outputs\n",
    "bridges_df.to_csv(r\"C:\\Users\\albe9057\\Documents\\GitHub\\ArcGISPythonAPI_Projects\\Presentation\\FedGIS2018\\bridges_analyzed.csv\")\n",
    "# bridges_processed_csv = r\"C:\\Users\\albe9057\\Documents\\GitHub\\ArcGISPythonAPI_Projects\\Presentation\\FedGIS2018\\bridges_processed.csv\"\n",
    "bridges_analyzed_csv = r\"C:\\Users\\albe9057\\Documents\\GitHub\\ArcGISPythonAPI_Projects\\Presentation\\FedGIS2018\\bridges_analyzed.csv\"\n",
    "# Publish csv item\n",
    "bridges_analyzed_csv_item = gis.content.add({}, bridges_analyzed_csv)\n",
    "# Convert csv item to hosted layer in ArcGIS Online\n",
    "bridges_analyzed_lyr = bridges_analyzed_csv_item.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### The ArcGIS API for Python let us document, design, prototype, and run our workflow helped us get to an analysis that can now be deployed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Interpret Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(analyzed_bridges_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Map of Analyzed Bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analyzed_bridges_map = gis.map('Fairfax County', zoomlevel=8)\n",
    "analyzed_bridges_map.basemap = 'gray-vector'\n",
    "display(analyzed_bridges_map)\n",
    "analyzed_bridges_map.add_layer(analyzed_bridges_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Map of Most Critical Bridge, with nominal commutes, and alternative commutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "most_critical_bridge_map = gis.map('Fairfax County', zoomlevel=8)\n",
    "most_critical_bridge_map.basemap = 'gray-vector'\n",
    "display(most_critical_bridge_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. Repeat as Necessary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Present the Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Make a Decision:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
