{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\">ArcGIS API for Python: Traffic and Pedestrian Activity Detection</span>\n",
    "\n",
    "![detection](../img/DCActivityDetection.gif \"CityWideDetection\")\n",
    "\n",
    "## Integrating ArcGIS with TensorFlow Deep Learning using the ArcGIS API for Python\n",
    "\n",
    "## Washington, DC Camera Network Activity Capturing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of integration between ArcGIS and deep learning frameworks like TensorFlow using the ArcGIS API for Python.\n",
    "\n",
    "<img src=\"../img/ArcGIS_ML_Integration.png\" style=\"width: 75%\"></img>\n",
    "\n",
    "We will leverage a model to detect objects on a live video feed from youtube, and use these to update a feature service on a web GIS in real-time. As people, cars, trucks, and buses are detected on the feed, the feature will be updated to reflect the detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import getpass\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import arcgis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Connection to ArcGIS Online via ArcGIS API for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gis_url = \"\"   # Replace with gis URL\n",
    "username = \"\"  # Replace with username\n",
    "gis = arcgis.gis.GIS(gis_url, username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: SSD Mobilenet on COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function that takes the detection graph output tensor (np arrays), stacks the classes and scores, and determines if the class for a person (1) is available within a certain score and within a certain amount of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def object_counter(classes_arr, scores_arr, score_thresh=0.3):\n",
    "    # Process the numpy array of classes from the model\n",
    "    stacked_arr = np.stack((classes_arr, scores_arr), axis=-1)\n",
    "    # Convert to pandas dataframe for easier querying\n",
    "    detection_df = pd.DataFrame(stacked_arr)\n",
    "    # Retrieve total count of cars with score threshold above param value\n",
    "    detected_cars = detection_df[(detection_df[0] == 3.0) & (detection_df[1] > score_thresh)]\n",
    "    detected_people =  detection_df[(detection_df[0] == 1.0) & (detection_df[1] > score_thresh)]\n",
    "    detected_bicycles =  detection_df[(detection_df[0] == 2.0) & (detection_df[1] > score_thresh)]\n",
    "    detected_motorcycles =  detection_df[(detection_df[0] == 4.0) & (detection_df[1] > score_thresh)]\n",
    "    detected_buses =  detection_df[(detection_df[0] == 6.0) & (detection_df[1] > score_thresh)]\n",
    "    detected_trucks =  detection_df[(detection_df[0] == 8.0) & (detection_df[1] > score_thresh)]\n",
    "    \n",
    "    car_count = len(detected_cars)\n",
    "    people_count = len(detected_people)\n",
    "    bicycle_count = len(detected_bicycles)\n",
    "    motorcycle_count = len(detected_motorcycles)\n",
    "    bus_count = len(detected_buses)\n",
    "    truck_count = len(detected_trucks)\n",
    "\n",
    "    return car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count\n",
    "\n",
    "def return_lat(row):\n",
    "    return row['location']['latitude']\n",
    "\n",
    "def return_lon(row):\n",
    "    return row['location']['longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Camera Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TrafficLand API source JSON\n",
    "trafficland_API_key = os.environ['TRAFFICLAND_API_KEY']  # \n",
    "source_json = r\"http://api.trafficland.com/v1.5/json/video_feeds?system=ddot&key={0}\".format(trafficland_API_key)\n",
    "df = pd.read_json(source_json)\n",
    "ddot_df = df.loc[df.provider == 'DDOT']\n",
    "# Edit the ddot_df to make a feature service using the API\n",
    "ddot_df['latitude'] = ddot_df.apply(lambda row: return_lat(row), axis=1)\n",
    "ddot_df['longitude'] = ddot_df.apply(lambda row: return_lon(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Camera Iteration Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "jpeg_size = \"halfJpeg\" # Other Options: halfJpeg; fullJpeg; hugeJpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1: Use existing feature service and send model outputs as updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RT Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# object_point_srvc = gis.content.search(\"DDOT Traffic Cameras\", item_type=\"feature service\")[1]\n",
    "# object_point_srvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_point_srvc = gis.content.search(\"DDOT_TrafficCameras_CityNetwork\", item_type=\"feature service\")[0]\n",
    "object_point_srvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert our existing service into a pandas dataframe\n",
    "object_point_lyr = object_point_srvc.layers[0]\n",
    "obj_fset = object_point_lyr.query()  #querying without any conditions returns all the features\n",
    "obj_df = obj_fset.df\n",
    "all_features = obj_fset.features\n",
    "original_feature = all_features[1]\n",
    "feature_to_be_updated = deepcopy(original_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Update with Attachments and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overwrite_attachment = True\n",
    "\n",
    "upload_source = False\n",
    "\n",
    "write_trends = True\n",
    "\n",
    "reset_trends = True\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for iteration in range(1000):\n",
    "            # TrafficLand API source JSON\n",
    "            trafficland_API_key = os.environ['TRAFFICLAND_API_KEY']  # \n",
    "            source_json = r\"http://api.trafficland.com/v1.5/json/video_feeds?system=ddot&key={0}\".format(trafficland_API_key)\n",
    "            df = pd.read_json(source_json)\n",
    "            ddot_df = df.loc[df.provider == 'DDOT']\n",
    "            \n",
    "            for ix in range(1,110):\n",
    "                print(\"Processing camera {0} of 110...\".format(str(ix)))\n",
    "\n",
    "                # Retrieve camera information\n",
    "                camera_jpeg_url = ddot_df.iloc[ix]['content']['hugeJpeg']\n",
    "                camera_name = ddot_df.iloc[ix]['name']\n",
    "                camera_id = ddot_df.iloc[ix]['publicId']\n",
    "                \n",
    "                # Retrieve the camera image\n",
    "                camera_response = requests.get(camera_jpeg_url)\n",
    "                \n",
    "#                 # Perform attachment of source image\n",
    "                if upload_source:\n",
    "                    streamed_response = requests.get(camera_jpeg_url, stream=True)\n",
    "                    with open('source.jpg', 'wb') as out_file:\n",
    "                        shutil.copyfileobj(streamed_response.raw, out_file)\n",
    "    #                 del response                \n",
    "\n",
    "                image = Image.open(BytesIO(camera_response.content))\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                      [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                      feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                      image_np,\n",
    "                      np.squeeze(boxes),\n",
    "                      np.squeeze(classes).astype(np.int32),\n",
    "                      np.squeeze(scores),\n",
    "                      category_index,\n",
    "                      use_normalized_coordinates=True,\n",
    "                      line_thickness=8,\n",
    "                      min_score_thresh=0.3\n",
    "                )\n",
    "                \n",
    "                car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count = object_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n",
    "                vehicle_count = car_count + motorcycle_count + bus_count + truck_count\n",
    "                total_count = vehicle_count + bicycle_count + people_count\n",
    "                \n",
    "                # Retrieve the feature from the feature layer to update\n",
    "                obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "                all_features = obj_fset.features\n",
    "                original_feature = all_features[0]\n",
    "                feature_to_be_updated = deepcopy(original_feature)\n",
    "                \n",
    "                features_for_update = []\n",
    "                feature_to_be_updated.attributes['rt_object_count'] = total_count\n",
    "                feature_to_be_updated.attributes['rt_vehicle_count'] = vehicle_count\n",
    "                feature_to_be_updated.attributes['rt_car_count'] = car_count\n",
    "                feature_to_be_updated.attributes['rt_bus_count'] = bus_count\n",
    "                feature_to_be_updated.attributes['rt_truck_count'] = truck_count\n",
    "                feature_to_be_updated.attributes['rt_motorcycle_count'] = motorcycle_count\n",
    "                feature_to_be_updated.attributes['rt_pedestrian_count'] = people_count\n",
    "                feature_to_be_updated.attributes['rt_bicycle_count'] = bicycle_count\n",
    "                \n",
    "                feature_to_be_updated.attributes['source_image'] = camera_jpeg_url\n",
    "                \n",
    "                # Perform Trend Process\n",
    "                if write_trends:\n",
    "                    \n",
    "                    # If the trend needs to be reset\n",
    "                    if reset_trends and iteration==0:\n",
    "                        print(\"Resetting trends...\")\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_car'] = car_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_ped'] = people_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_bus'] = bus_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_trck'] = truck_count\n",
    "                        \n",
    "                        histval_car = car_count\n",
    "                        histval_ped = people_count\n",
    "                        histval_bus = bus_count\n",
    "                        histval_truck = truck_count\n",
    "\n",
    "                    # If the trend does not need to be reset\n",
    "                    else:\n",
    "                        histval_car = feature_to_be_updated.attributes['histval_10am_th_car']\n",
    "                        histval_ped = feature_to_be_updated.attributes['histval_10am_th_ped']\n",
    "                        histval_bus = feature_to_be_updated.attributes['histval_10am_th_bus']\n",
    "                        histval_truck = feature_to_be_updated.attributes['histval_10am_th_trck']\n",
    "                        \n",
    "                        if histval_car == None:\n",
    "                            histval_car = car_count\n",
    "                        if histval_bus == None:\n",
    "                            histval_bus = bus_count\n",
    "                        if histval_truck == None:\n",
    "                            histval_truck = truck_count\n",
    "                        if histval_ped == None:\n",
    "                            histval_ped = people_count                            \n",
    "                    \n",
    "                        # Calculate the new trend value and store it for the new update\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_car'] = (car_count + histval_car) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_ped'] = (people_count + histval_ped) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_bus'] = (bus_count + histval_bus) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_trck'] = (truck_count + histval_truck) / 2\n",
    "                        \n",
    "                    # Determine threshold percent, value, and status\n",
    "                    thrshpcnt_car = feature_to_be_updated.attributes['threshold_val_cars']\n",
    "                    thrshpcnt_ped = feature_to_be_updated.attributes['threshold_val_ped']\n",
    "                    thrshpcnt_bus = feature_to_be_updated.attributes['threshold_val_buses']\n",
    "                    thrshpcnt_truck = feature_to_be_updated.attributes['threshold_val_trck']\n",
    "                    \n",
    "                    # Perform writes to the threshold status field\n",
    "                    \n",
    "                    if car_count > (histval_car * thrshpcnt_car):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Above\"           \n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Below\"\n",
    "                        \n",
    "                    if people_count > (histval_ped * thrshpcnt_ped):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Above\"\n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Below\"                        \n",
    "                        \n",
    "                    if bus_count > (histval_bus * thrshpcnt_bus):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Above\"\n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Below\"                        \n",
    "                        \n",
    "                    if truck_count > (histval_truck * thrshpcnt_truck):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Above\"\n",
    "                    else:\n",
    "                        \n",
    "                        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Below\"                        \n",
    "                                               \n",
    "                # Store attribute updates and send edit request\n",
    "                features_for_update.append(feature_to_be_updated)\n",
    "                object_point_lyr.edit_features(updates=features_for_update)    \n",
    "        \n",
    "                # Perform attachment of detected image\n",
    "                scipy.misc.imsave('detected_objs.jpg', image_np)\n",
    "                obj_id = feature_to_be_updated.attributes['F__OBJECTID']\n",
    "                \n",
    "                if overwrite_attachment:\n",
    "                    for attachment in object_point_lyr.attachments.get_list(obj_id):\n",
    "                        object_point_lyr.attachments.delete(obj_id, attachment['id'])\n",
    "                                               \n",
    "                object_point_lyr.attachments.add(obj_id, 'detected_objs.jpg')\n",
    "                \n",
    "                if upload_source:\n",
    "                    object_point_lyr.attachments.add(obj_id, 'source.jpg')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Routine (WARNING: Will erase trends in data!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://esrifederal.maps.arcgis.com/home/webmap/viewer.html?webmap=255196da558749209dc63c07ffb38ae6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(1):\n",
    "    \n",
    "    features_for_update = []\n",
    "            \n",
    "    for ix in range(0,111):\n",
    "        print(\"Resetting values for camera {0} of 100...\".format(str(ix)))\n",
    "\n",
    "        # Retrieve camera information\n",
    "        camera_name = ddot_df.iloc[ix]['name']\n",
    "\n",
    "        # Retrieve the feature from the feature layer to update\n",
    "        obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "        all_features = obj_fset.features\n",
    "        original_feature = all_features[0]\n",
    "        feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "        \n",
    "        feature_to_be_updated.attributes['rt_object_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_vehicle_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_car_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_bus_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_truck_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_motorcycle_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_pedestrian_count'] = 0\n",
    "        feature_to_be_updated.attributes['rt_bicycle_count'] = 0\n",
    "        \n",
    "        feature_to_be_updated.attributes['histval_10am_th_car'] = None\n",
    "        feature_to_be_updated.attributes['histval_10am_th_ped'] = None\n",
    "        feature_to_be_updated.attributes['histval_10am_th_bus'] = None\n",
    "        feature_to_be_updated.attributes['histval_10am_th_trck'] = None\n",
    "        \n",
    "        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Not Tracked\"\n",
    "        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Not Tracked\" \n",
    "        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Not Tracked\" \n",
    "        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Not Tracked\"           \n",
    "\n",
    "        features_for_update.append(feature_to_be_updated)\n",
    "        \n",
    "    object_point_lyr.edit_features(updates=features_for_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set trend threshold percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh_percent = 2.0\n",
    "\n",
    "reset_trends = True\n",
    "\n",
    "for iteration in range(1):\n",
    "    \n",
    "    features_for_update = []\n",
    "            \n",
    "    for ix in range(0,111):\n",
    "        print(\"Setting trend threshold values for camera {0} of 111...\".format(str(ix)))\n",
    "\n",
    "        # Retrieve camera information\n",
    "        camera_name = ddot_df.iloc[ix]['name']\n",
    "\n",
    "        # Retrieve the feature from the feature layer to update\n",
    "        obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "        all_features = obj_fset.features\n",
    "        original_feature = all_features[0]\n",
    "        feature_to_be_updated = deepcopy(original_feature)\n",
    "        \n",
    "        feature_to_be_updated.attributes['threshold_val_cars'] = thresh_percent\n",
    "        feature_to_be_updated.attributes['threshold_val_ped'] = thresh_percent\n",
    "        feature_to_be_updated.attributes['threshold_val_buses'] = thresh_percent\n",
    "        feature_to_be_updated.attributes['threshold_val_trck'] = thresh_percent    \n",
    "        \n",
    "        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Not Tracked\"\n",
    "        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Not Tracked\" \n",
    "        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Not Tracked\" \n",
    "        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Not Tracked\" \n",
    "        \n",
    "        if reset_trends:\n",
    "            feature_to_be_updated.attributes['histval_10am_th_car'] = None\n",
    "            feature_to_be_updated.attributes['histval_10am_th_ped'] = None\n",
    "            feature_to_be_updated.attributes['histval_10am_th_bus'] = None\n",
    "            feature_to_be_updated.attributes['histval_10am_th_trck'] = None\n",
    "\n",
    "\n",
    "        features_for_update.append(feature_to_be_updated)\n",
    "        \n",
    "    object_point_lyr.edit_features(updates=features_for_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Demo Updates (Model, Attachments, Trends) Against Constitution Ave Event Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set thresh percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_feature_names = [\n",
    "    \"9th St @ Constitution Ave\",\n",
    "    \"12th St @ Constitution Ave\",\n",
    "    \"14th St @ Pennsylvania Ave\",\n",
    "    \"Pennsylvania Ave @ 7th St\",\n",
    "    \"Pennsylvania Ave @ 9th St\"\n",
    "]\n",
    "\n",
    "thresh_percent = 1.125\n",
    "\n",
    "features_for_update = []\n",
    "\n",
    "for event_feature_name in event_feature_names:\n",
    "    print(\"Setting thresh percent values for camera '{0}'...\".format(str(event_feature_name)))\n",
    "\n",
    "    record = ddot_df.loc[ddot_df.name == event_feature_name]\n",
    "\n",
    "    # Retrieve camera information\n",
    "    camera_name = record['name'].all()\n",
    "\n",
    "    # Retrieve the feature from the feature layer to update\n",
    "    obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "    all_features = obj_fset.features\n",
    "    original_feature = all_features[0]\n",
    "    feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "    feature_to_be_updated.attributes['threshold_val_cars'] = thresh_percent\n",
    "    feature_to_be_updated.attributes['threshold_val_ped'] = thresh_percent\n",
    "    feature_to_be_updated.attributes['threshold_val_buses'] = thresh_percent\n",
    "    feature_to_be_updated.attributes['threshold_val_trck'] = thresh_percent\n",
    "    \n",
    "    features_for_update.append(feature_to_be_updated)\n",
    "\n",
    "object_point_lyr.edit_features(updates=features_for_update)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset Trend Values for Event Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_feature_names = [\n",
    "    \"9th St @ Constitution Ave\",\n",
    "    \"12th St @ Constitution Ave\",\n",
    "    \"14th St @ Pennsylvania Ave\",\n",
    "    \"Pennsylvania Ave @ 7th St\",\n",
    "    \"Pennsylvania Ave @ 9th St\"\n",
    "]\n",
    "\n",
    "features_for_update = []\n",
    "\n",
    "for event_feature_name in event_feature_names:\n",
    "    print(\"Resetting values for camera '{0}'...\".format(str(event_feature_name)))\n",
    "\n",
    "    record = ddot_df.loc[ddot_df.name == event_feature_name]\n",
    "\n",
    "    # Retrieve camera information\n",
    "    camera_name = record['name'].all()\n",
    "\n",
    "    # Retrieve the feature from the feature layer to update\n",
    "    obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "    all_features = obj_fset.features\n",
    "    original_feature = all_features[0]\n",
    "    feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "\n",
    "    feature_to_be_updated.attributes['rt_object_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_vehicle_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_car_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_bus_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_truck_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_motorcycle_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_pedestrian_count'] = 0\n",
    "    feature_to_be_updated.attributes['rt_bicycle_count'] = 0\n",
    "\n",
    "    feature_to_be_updated.attributes['histval_10am_th_car'] = None\n",
    "    feature_to_be_updated.attributes['histval_10am_th_ped'] = None\n",
    "    feature_to_be_updated.attributes['histval_10am_th_bus'] = None\n",
    "    feature_to_be_updated.attributes['histval_10am_th_trck'] = None\n",
    "    \n",
    "    feature_to_be_updated.attributes['histval_10am_th_trck'] = None\n",
    "    \n",
    "    feature_to_be_updated.attributes['thrsh_status_cars'] = \"Not Tracked\"\n",
    "    feature_to_be_updated.attributes['thrsh_status_ped'] = \"Not Tracked\" \n",
    "    feature_to_be_updated.attributes['thrsh_status_bus'] = \"Not Tracked\" \n",
    "    feature_to_be_updated.attributes['thrsh_status_trck'] = \"Not Tracked\"      \n",
    "\n",
    "    features_for_update.append(feature_to_be_updated)\n",
    "\n",
    "object_point_lyr.edit_features(updates=features_for_update)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demo Event Features Against Screencap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1920 x 1080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_feature_name = \"9th St @ Constitution Ave\"\n",
    "\n",
    "overwrite_attachment = True\n",
    "\n",
    "write_trends = True\n",
    "\n",
    "reset_trends = True\n",
    "\n",
    "iteration=0\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        while True: \n",
    "            \n",
    "            record = ddot_df.loc[ddot_df.name == event_feature_name]\n",
    "\n",
    "            # Retrieve camera information\n",
    "            camera_name = record['name'].all()\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np = np.array(ImageGrab.grab(bbox=(0,510,960,1020)))\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "                  [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                  feed_dict={image_tensor: image_np_expanded})\n",
    "            \n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=8, min_score_thresh=0.5)\n",
    "            \n",
    "            cv2.imshow('object detection', cv2.resize(image_np, (960,510), interpolation=cv2.INTER_CUBIC))\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break            \n",
    "\n",
    "            car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count = object_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n",
    "            vehicle_count = car_count + motorcycle_count + bus_count + truck_count\n",
    "            total_count = vehicle_count + bicycle_count + people_count\n",
    "\n",
    "            # Retrieve the feature from the feature layer to update\n",
    "            obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "            all_features = obj_fset.features\n",
    "            original_feature = all_features[0]\n",
    "            feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "            features_for_update = []\n",
    "            feature_to_be_updated.attributes['rt_object_count'] = total_count\n",
    "            feature_to_be_updated.attributes['rt_vehicle_count'] = vehicle_count\n",
    "            feature_to_be_updated.attributes['rt_car_count'] = car_count\n",
    "            feature_to_be_updated.attributes['rt_bus_count'] = bus_count\n",
    "            feature_to_be_updated.attributes['rt_truck_count'] = truck_count\n",
    "            feature_to_be_updated.attributes['rt_motorcycle_count'] = motorcycle_count\n",
    "            feature_to_be_updated.attributes['rt_pedestrian_count'] = people_count\n",
    "            feature_to_be_updated.attributes['rt_bicycle_count'] = bicycle_count\n",
    "\n",
    "            # Perform Trend Process\n",
    "            if write_trends:\n",
    "\n",
    "                # If the trend needs to be reset\n",
    "                if reset_trends and iteration==0:\n",
    "                    print(\"Resetting trends...\")\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_car'] = car_count\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_ped'] = people_count\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_bus'] = bus_count\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_trck'] = truck_count\n",
    "\n",
    "                    histval_car = car_count\n",
    "                    histval_ped = people_count\n",
    "                    histval_bus = bus_count\n",
    "                    histval_truck = truck_count\n",
    "\n",
    "                # If the trend does not need to be reset\n",
    "                else:\n",
    "                    histval_car = feature_to_be_updated.attributes['histval_10am_th_car']\n",
    "                    histval_ped = feature_to_be_updated.attributes['histval_10am_th_ped']\n",
    "                    histval_bus = feature_to_be_updated.attributes['histval_10am_th_bus']\n",
    "                    histval_truck = feature_to_be_updated.attributes['histval_10am_th_trck']\n",
    "\n",
    "                    if histval_car == None:\n",
    "                        histval_car = car_count\n",
    "                    if histval_ped == None:\n",
    "                        histval_ped = people_count                           \n",
    "                    if histval_bus == None:\n",
    "                        histval_bus = bus_count\n",
    "                    if histval_truck == None:\n",
    "                        histval_truck = truck_count\n",
    "                         \n",
    "                    # Calculate the new trend value and store it for the new update\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_car'] = (car_count + histval_car) / 2\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_ped'] = (people_count + histval_ped) / 2\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_bus'] = (bus_count + histval_bus) / 2\n",
    "                    feature_to_be_updated.attributes['histval_10am_th_trck'] = (truck_count + histval_truck) / 2\n",
    "\n",
    "                # Determine threshold percent, value, and status\n",
    "                thrshpcnt_car = feature_to_be_updated.attributes['threshold_val_cars']\n",
    "                thrshpcnt_ped = feature_to_be_updated.attributes['threshold_val_ped']\n",
    "                thrshpcnt_bus = feature_to_be_updated.attributes['threshold_val_buses']\n",
    "                thrshpcnt_truck = feature_to_be_updated.attributes['threshold_val_trck']\n",
    "\n",
    "                # Perform writes to the threshold status field\n",
    "\n",
    "                if car_count > (histval_car * thrshpcnt_car):\n",
    "                    feature_to_be_updated.attributes['thrsh_status_cars'] = \"Above\"           \n",
    "                else:\n",
    "                    feature_to_be_updated.attributes['thrsh_status_cars'] = \"Below\"\n",
    "\n",
    "                if people_count > (histval_ped * thrshpcnt_ped):\n",
    "                    feature_to_be_updated.attributes['thrsh_status_ped'] = \"Above\"\n",
    "                else:\n",
    "                    feature_to_be_updated.attributes['thrsh_status_ped'] = \"Below\"                        \n",
    "\n",
    "                if bus_count > (histval_bus * thrshpcnt_bus):\n",
    "                    feature_to_be_updated.attributes['thrsh_status_bus'] = \"Above\"\n",
    "                else:\n",
    "                    feature_to_be_updated.attributes['thrsh_status_bus'] = \"Below\"                        \n",
    "\n",
    "                if truck_count > (histval_truck * thrshpcnt_truck):\n",
    "                    feature_to_be_updated.attributes['thrsh_status_trck'] = \"Above\"\n",
    "                    \"Passed truck thresh\"\n",
    "                else:\n",
    "                    feature_to_be_updated.attributes['thrsh_status_trck'] = \"Below\"                        \n",
    "\n",
    "            # Store attribute updates and send edit request\n",
    "            features_for_update.append(feature_to_be_updated)\n",
    "            object_point_lyr.edit_features(updates=features_for_update)    \n",
    "\n",
    "            # Perform attachment of detected image\n",
    "            scipy.misc.imsave('detected_objs.jpg', image_np)\n",
    "            obj_id = feature_to_be_updated.attributes['F__OBJECTID']\n",
    "\n",
    "            if overwrite_attachment:\n",
    "                for attachment in object_point_lyr.attachments.get_list(obj_id):\n",
    "                    object_point_lyr.attachments.delete(obj_id, attachment['id'])\n",
    "\n",
    "            object_point_lyr.attachments.add(obj_id, 'detected_objs.jpg')\n",
    "               \n",
    "            iteration+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_feature_names = [\n",
    "    \"9th St @ Constitution Ave\",\n",
    "    \"12th St @ Constitution Ave\",\n",
    "    \"14th St @ Pennsylvania Ave\",\n",
    "    \"Pennsylvania Ave @ 7th St\",\n",
    "    \"Pennsylvania Ave @ 9th St\"\n",
    "]\n",
    "\n",
    "overwrite_attachment = True\n",
    "\n",
    "write_trends = True\n",
    "\n",
    "reset_trends = True\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            for event_feature_name in event_feature_names:\n",
    "                print(\"Processing camera '{0}' (Iteration {1})...\".format(str(camera_name), str(iteration)))\n",
    "                record = ddot_df.loc[ddot_df.name == event_feature_name]\n",
    "\n",
    "                # Retrieve camera information\n",
    "                camera_name = record['name'].all()\n",
    "\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np = np.array(ImageGrab.grab(bbox=(0,510,960,1020)))\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "                (boxes, scores, classes, num) = sess.run(\n",
    "                      [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                      feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                  image_np,\n",
    "                  np.squeeze(boxes),\n",
    "                  np.squeeze(classes).astype(np.int32),\n",
    "                  np.squeeze(scores),\n",
    "                  category_index,\n",
    "                  use_normalized_coordinates=True,\n",
    "                  line_thickness=8, min_score_thresh=0.5)\n",
    "\n",
    "                cv2.imshow('object detection', cv2.resize(image_np, (960,510), interpolation=cv2.INTER_CUBIC))\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break            \n",
    "\n",
    "                car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count = object_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n",
    "                vehicle_count = car_count + motorcycle_count + bus_count + truck_count\n",
    "                total_count = vehicle_count + bicycle_count + people_count\n",
    "\n",
    "                # Retrieve the feature from the feature layer to update\n",
    "                obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "                all_features = obj_fset.features\n",
    "                original_feature = all_features[0]\n",
    "                feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "                features_for_update = []\n",
    "                feature_to_be_updated.attributes['rt_object_count'] = total_count\n",
    "                feature_to_be_updated.attributes['rt_vehicle_count'] = vehicle_count\n",
    "                feature_to_be_updated.attributes['rt_car_count'] = car_count\n",
    "                feature_to_be_updated.attributes['rt_bus_count'] = bus_count\n",
    "                feature_to_be_updated.attributes['rt_truck_count'] = truck_count\n",
    "                feature_to_be_updated.attributes['rt_motorcycle_count'] = motorcycle_count\n",
    "                feature_to_be_updated.attributes['rt_pedestrian_count'] = people_count\n",
    "                feature_to_be_updated.attributes['rt_bicycle_count'] = bicycle_count\n",
    "\n",
    "                feature_to_be_updated.attributes['source_image'] = camera_jpeg_url\n",
    "\n",
    "                # Perform Trend Process\n",
    "                if write_trends:\n",
    "\n",
    "                    # If the trend needs to be reset\n",
    "                    if reset_trends and iteration==0:\n",
    "                        print(\"Resetting trends...\")\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_car'] = car_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_ped'] = people_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_bus'] = bus_count\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_trck'] = truck_count\n",
    "\n",
    "                        histval_car = car_count\n",
    "                        histval_ped = people_count\n",
    "                        histval_bus = bus_count\n",
    "                        histval_truck = truck_count\n",
    "\n",
    "                    # If the trend does not need to be reset\n",
    "                    else:\n",
    "                        histval_car = feature_to_be_updated.attributes['histval_10am_th_car']\n",
    "                        histval_ped = feature_to_be_updated.attributes['histval_10am_th_ped']\n",
    "                        histval_bus = feature_to_be_updated.attributes['histval_10am_th_bus']\n",
    "                        histval_truck = feature_to_be_updated.attributes['histval_10am_th_trck']\n",
    "\n",
    "                        if histval_car == None:\n",
    "                            histval_car = car_count\n",
    "                        if histval_ped == None:\n",
    "                            histval_ped = people_count                           \n",
    "                        if histval_bus == None:\n",
    "                            histval_bus = bus_count\n",
    "                        if histval_truck == None:\n",
    "                            histval_truck = truck_count\n",
    "\n",
    "                        # Calculate the new trend value and store it for the new update\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_car'] = (car_count + histval_car) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_ped'] = (people_count + histval_ped) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_bus'] = (bus_count + histval_bus) / 2\n",
    "                        feature_to_be_updated.attributes['histval_10am_th_trck'] = (truck_count + histval_truck) / 2\n",
    "\n",
    "                    # Determine threshold percent, value, and status\n",
    "                    thrshpcnt_car = feature_to_be_updated.attributes['threshold_val_cars']\n",
    "                    thrshpcnt_ped = feature_to_be_updated.attributes['threshold_val_ped']\n",
    "                    thrshpcnt_bus = feature_to_be_updated.attributes['threshold_val_buses']\n",
    "                    thrshpcnt_truck = feature_to_be_updated.attributes['threshold_val_trck']\n",
    "\n",
    "                    # Perform writes to the threshold status field\n",
    "\n",
    "                    if car_count > (histval_car * thrshpcnt_car):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Above\"           \n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_cars'] = \"Below\"\n",
    "\n",
    "                    if people_count > (histval_ped * thrshpcnt_ped):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Above\"\n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_ped'] = \"Below\"                        \n",
    "\n",
    "                    if bus_count > (histval_bus * thrshpcnt_bus):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Above\"\n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_bus'] = \"Below\"                        \n",
    "\n",
    "                    if truck_count > (histval_truck * thrshpcnt_truck):\n",
    "                        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Above\"\n",
    "                    else:\n",
    "                        feature_to_be_updated.attributes['thrsh_status_trck'] = \"Below\"                        \n",
    "\n",
    "                # Store attribute updates and send edit request\n",
    "                features_for_update.append(feature_to_be_updated)\n",
    "                object_point_lyr.edit_features(updates=features_for_update)    \n",
    "\n",
    "                # Perform attachment of detected image\n",
    "                scipy.misc.imsave('detected_objs.jpg', image_np)\n",
    "                obj_id = feature_to_be_updated.attributes['F__OBJECTID']\n",
    "\n",
    "                if overwrite_attachment:\n",
    "                    for attachment in object_point_lyr.attachments.get_list(obj_id):\n",
    "                        object_point_lyr.attachments.delete(obj_id, attachment['id'])\n",
    "\n",
    "                object_point_lyr.attachments.add(obj_id, 'detected_objs.jpg')\n",
    "\n",
    "                if upload_source:\n",
    "                    object_point_lyr.attachments.add(obj_id, 'source.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demo Event Features Against Traffic Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_event_features = True\n",
    "\n",
    "event_feature_names = [\n",
    "    \"9th St @ Constitution Ave\",\n",
    "    \"12th St @ Constitution Ave\"\n",
    "]\n",
    "\n",
    "overwrite_attachment = True\n",
    "\n",
    "upload_source = False\n",
    "\n",
    "write_trends = True\n",
    "\n",
    "reset_trends = True\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for iteration in range(1, 21):\n",
    "            # TrafficLand API source JSON\n",
    "            source_json = r\"http://api.trafficland.com/v1.5/json/video_feeds?system=ddot&key=1594c8892d7fbd18181a8a6a44958b28\"\n",
    "            df = pd.read_json(source_json)\n",
    "            ddot_df = df.loc[df.provider == 'DDOT']\n",
    "            \n",
    "            if demo_event_features:\n",
    "                for event_feature_name in event_feature_names:\n",
    "                    print(\"Processing camera '{0}' (Iteration {1})...\".format(str(camera_name), str(iteration)))\n",
    "                    \n",
    "                    record = ddot_df.loc[ddot_df.name == event_feature_name]\n",
    "                    \n",
    "                    # Retrieve camera information\n",
    "                    camera_jpeg_url = record['content'].all()['hugeJpeg']\n",
    "                    camera_name = record['name'].all()\n",
    "                    camera_id = record['publicId'].all()\n",
    "\n",
    "                    # Retrieve the camera image\n",
    "                    camera_response = requests.get(camera_jpeg_url)\n",
    "\n",
    "    #                 # Perform attachment of source image\n",
    "                    if upload_source:\n",
    "                        streamed_response = requests.get(camera_jpeg_url, stream=True)\n",
    "                        with open('source.jpg', 'wb') as out_file:\n",
    "                            shutil.copyfileobj(streamed_response.raw, out_file)\n",
    "        #                 del response                \n",
    "\n",
    "                    image = Image.open(BytesIO(camera_response.content))\n",
    "                    image_np = load_image_into_numpy_array(image)\n",
    "                    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "                    (boxes, scores, classes, num) = sess.run(\n",
    "                          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                          feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                          image_np,\n",
    "                          np.squeeze(boxes),\n",
    "                          np.squeeze(classes).astype(np.int32),\n",
    "                          np.squeeze(scores),\n",
    "                          category_index,\n",
    "                          use_normalized_coordinates=True,\n",
    "                          line_thickness=8)\n",
    "\n",
    "                    car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count = object_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n",
    "                    vehicle_count = car_count + motorcycle_count + bus_count + truck_count\n",
    "                    total_count = vehicle_count + bicycle_count + people_count\n",
    "\n",
    "                    # Retrieve the feature from the feature layer to update\n",
    "                    obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\", return_geometry=False)  \n",
    "                    all_features = obj_fset.features\n",
    "                    original_feature = all_features[0]\n",
    "                    feature_to_be_updated = deepcopy(original_feature)\n",
    "\n",
    "                    features_for_update = []\n",
    "                    feature_to_be_updated.attributes['rt_object_count'] = total_count\n",
    "                    feature_to_be_updated.attributes['rt_vehicle_count'] = vehicle_count\n",
    "                    feature_to_be_updated.attributes['rt_car_count'] = car_count\n",
    "                    feature_to_be_updated.attributes['rt_bus_count'] = bus_count\n",
    "                    feature_to_be_updated.attributes['rt_truck_count'] = truck_count\n",
    "                    feature_to_be_updated.attributes['rt_motorcycle_count'] = motorcycle_count\n",
    "                    feature_to_be_updated.attributes['rt_pedestrian_count'] = people_count\n",
    "                    feature_to_be_updated.attributes['rt_bicycle_count'] = bicycle_count\n",
    "\n",
    "                    feature_to_be_updated.attributes['source_image'] = camera_jpeg_url\n",
    "\n",
    "                    # Perform Trend Process\n",
    "                    if write_trends:\n",
    "\n",
    "                        # If the trend needs to be reset\n",
    "                        if reset_trends and iteration==0:\n",
    "                            print(\"Resetting trends...\")\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_car'] = car_count\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_ped'] = people_count\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_bus'] = bus_count\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_trck'] = truck_count\n",
    "\n",
    "                            histval_car = car_count\n",
    "                            histval_ped = people_count\n",
    "                            histval_bus = bus_count\n",
    "                            histval_truck = truck_count\n",
    "\n",
    "                        # If the trend does not need to be reset\n",
    "                        else:\n",
    "                            histval_car = feature_to_be_updated.attributes['histval_10am_th_car']\n",
    "                            histval_ped = feature_to_be_updated.attributes['histval_10am_th_ped']\n",
    "                            histval_bus = feature_to_be_updated.attributes['histval_10am_th_bus']\n",
    "                            histval_truck = feature_to_be_updated.attributes['histval_10am_th_trck']\n",
    "\n",
    "                            if histval_car == None:\n",
    "                                histval_car = car_count\n",
    "                            if histval_bus == None:\n",
    "                                histval_bus = bus_count\n",
    "                            if histval_truck == None:\n",
    "                                histval_truck = truck_count\n",
    "                            if histval_ped == None:\n",
    "                                histval_ped = people_count                            \n",
    "\n",
    "                            # Calculate the new trend value and store it for the new update\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_car'] = (car_count + histval_car) / 2\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_ped'] = (people_count + histval_ped) / 2\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_bus'] = (bus_count + histval_bus) / 2\n",
    "                            feature_to_be_updated.attributes['histval_10am_th_trck'] = (truck_count + histval_truck) / 2\n",
    "\n",
    "                        # Determine threshold percent, value, and status\n",
    "                        thrshpcnt_car = feature_to_be_updated.attributes['threshold_val_cars']\n",
    "                        thrshpcnt_ped = feature_to_be_updated.attributes['threshold_val_ped']\n",
    "                        thrshpcnt_bus = feature_to_be_updated.attributes['threshold_val_buses']\n",
    "                        thrshpcnt_truck = feature_to_be_updated.attributes['threshold_val_trck']\n",
    "\n",
    "                        # Perform writes to the threshold status field\n",
    "\n",
    "                        if car_count > (histval_car * thrshpcnt_car):\n",
    "                            feature_to_be_updated.attributes['thrsh_status_cars'] = \"Above\"           \n",
    "                        else:\n",
    "                            feature_to_be_updated.attributes['thrsh_status_cars'] = \"Below\"\n",
    "\n",
    "                        if people_count > (histval_ped * thrshpcnt_ped):\n",
    "                            feature_to_be_updated.attributes['thrsh_status_ped'] = \"Above\"\n",
    "                        else:\n",
    "                            feature_to_be_updated.attributes['thrsh_status_ped'] = \"Below\"                        \n",
    "\n",
    "                        if bus_count > (histval_bus * thrshpcnt_bus):\n",
    "                            feature_to_be_updated.attributes['thrsh_status_bus'] = \"Above\"\n",
    "                        else:\n",
    "                            feature_to_be_updated.attributes['thrsh_status_bus'] = \"Below\"                        \n",
    "\n",
    "                        if truck_count > (histval_truck * thrshpcnt_truck):\n",
    "                            feature_to_be_updated.attributes['thrsh_status_trck'] = \"Above\"\n",
    "                        else:\n",
    "                            feature_to_be_updated.attributes['thrsh_status_trck'] = \"Below\"                        \n",
    "\n",
    "                    # Store attribute updates and send edit request\n",
    "                    features_for_update.append(feature_to_be_updated)\n",
    "                    object_point_lyr.edit_features(updates=features_for_update)    \n",
    "\n",
    "                    # Perform attachment of detected image\n",
    "                    scipy.misc.imsave('detected_objs.jpg', image_np)\n",
    "                    obj_id = feature_to_be_updated.attributes['F__OBJECTID']\n",
    "\n",
    "                    if overwrite_attachment:\n",
    "                        for attachment in object_point_lyr.attachments.get_list(obj_id):\n",
    "                            object_point_lyr.attachments.delete(obj_id, attachment['id'])\n",
    "\n",
    "                    object_point_lyr.attachments.add(obj_id, 'detected_objs.jpg')\n",
    "\n",
    "                    if upload_source:\n",
    "                        object_point_lyr.attachments.add(obj_id, 'source.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2: Perform Updates Along Constitution Avenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform run on subset along Constitution Ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_point_srvc_const_ave = gis.content.search(\"DC_TrafficCameras_ConstitutionAve\", item_type=\"feature service\")[0]\n",
    "object_point_srvc_const_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert our existing service into a pandas dataframe\n",
    "object_point_lyr_const_ave = object_point_srvc_const_ave.layers[0]\n",
    "obj_fset_const_ave = object_point_lyr_const_ave.query()  #querying without any conditions returns all the features\n",
    "obj_df_const_ave = obj_fset_const_ave.df\n",
    "constitutionave_names_list = obj_df_const_ave.name.tolist()\n",
    "ddot_constitutionave_df = ddot_df[ddot_df.name.isin(constitutionave_names_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://esrifederal.maps.arcgis.com/home/webmap/viewer.html?webmap=e081b389ac8d4bdb817c34dbe78a5fc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3: Trend-setter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_point_srvc = gis.content.search(\"DC_TrafficCameras_HIST_ConstAve\", item_type=\"feature service\")[0]\n",
    "object_point_srvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert our existing service into a pandas dataframe\n",
    "object_point_lyr = object_point_srvc.layers[0]\n",
    "obj_fset = object_point_lyr.query()  #querying without any conditions returns all the features\n",
    "obj_df = obj_fset.df\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With auto-refresh of source JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        \n",
    "        for refresh_iteration in range(10):\n",
    "            print(\"Refresh iteration {0}...\".format(str(refresh_iteration)))\n",
    "            \n",
    "            # TrafficLand API source JSON\n",
    "            source_json = r\"http://api.trafficland.com/v1.5/json/video_feeds?system=ddot&key=1594c8892d7fbd18181a8a6a44958b28\"\n",
    "            df = pd.read_json(source_json)\n",
    "            ddot_df = df.loc[df.provider == 'DDOT']\n",
    "            ddot_constitutionave_df = ddot_df[ddot_df.name.isin(constitutionave_names_list)]\n",
    "            \n",
    "            for iteration in range(100):\n",
    "                print(\"Iteration: {0} of {1}\".format(str(iteration), str(100)))\n",
    "\n",
    "                for ix, row in enumerate(ddot_constitutionave_df.iterrows()):\n",
    "\n",
    "                    # Retrieve camera information\n",
    "                    camera_jpeg_url = ddot_constitutionave_df.iloc[ix]['content']['hugeJpeg']\n",
    "                    camera_name = ddot_constitutionave_df.iloc[ix]['name']\n",
    "                    camera_id = ddot_constitutionave_df.iloc[ix]['publicId']\n",
    "\n",
    "                    # Retrieve the camera image\n",
    "                    camera_response = requests.get(camera_jpeg_url)\n",
    "\n",
    "                    image = Image.open(BytesIO(camera_response.content))\n",
    "                    image_np = load_image_into_numpy_array(image)\n",
    "                    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "                    (boxes, scores, classes, num) = sess.run(\n",
    "                          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                          feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                          image_np,\n",
    "                          np.squeeze(boxes),\n",
    "                          np.squeeze(classes).astype(np.int32),\n",
    "                          np.squeeze(scores),\n",
    "                          category_index,\n",
    "                          use_normalized_coordinates=True,\n",
    "                          line_thickness=8)\n",
    "\n",
    "                    car_count, people_count, bicycle_count, motorcycle_count, bus_count, truck_count = object_counter(np.squeeze(classes).astype(np.int32), np.squeeze(scores))\n",
    "                    vehicle_count = car_count + motorcycle_count + bus_count + truck_count\n",
    "                    total_count = vehicle_count + bicycle_count + people_count\n",
    "\n",
    "                    # Retrieve the feature from the feature layer to update\n",
    "                    obj_fset = object_point_lyr.query(where=\"\"\"name = '\"\"\"+camera_name+\"\"\"'\"\"\")  \n",
    "                    all_features = obj_fset.features\n",
    "                    original_feature = all_features[0]\n",
    "\n",
    "                    features_to_be_added = []\n",
    "                    new_feature = deepcopy(original_feature)\n",
    "\n",
    "                    new_feature.attributes['rt_object_count'] = total_count\n",
    "                    new_feature.attributes['rt_vehicle_count'] = vehicle_count\n",
    "                    new_feature.attributes['rt_car_count'] = car_count\n",
    "                    new_feature.attributes['rt_bus_count'] = bus_count\n",
    "                    new_feature.attributes['rt_truck_count'] = truck_count\n",
    "                    new_feature.attributes['rt_motorcycle_count'] = motorcycle_count\n",
    "                    new_feature.attributes['rt_pedestrian_count'] = people_count\n",
    "                    new_feature.attributes['rt_bicycle_count'] = bicycle_count\n",
    "                    new_feature.attributes['recording_id'] = \"Cam{0}_{1}\".format(str(ix),\n",
    "                                                                                 str(datetime.now().strftime(\"%m%d%y_%H%M%S\")))\n",
    "                    new_feature.attributes['observation_time'] = datetime.now().strftime(\"%m/%d/%y %H:%M:%S\")\n",
    "\n",
    "                    #add this to the list of features to be updated\n",
    "                    features_to_be_added.append(new_feature)\n",
    "\n",
    "                    object_point_lyr.edit_features(adds = features_to_be_added) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
