{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Self-Aggregating Map Layer using GeoAnalytics\n",
    "\n",
    "This notebook will complete the following:\n",
    "\n",
    "- Connect to your Enterprise portal\n",
    "- Search through your big data file shares for your dataset of interest\n",
    "- Run the GeoAnalytics Tool Copy to Data Store\n",
    "- Publish the results of the tool as a Map Image Layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules to use the ArcGIS API for Python \n",
    "# and the GeoAnalytics module\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "import arcgis.geoanalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify this notebook to be used in your organization, set the following variables:\n",
    "\n",
    "- The portal URL, username and password. The member is required to have [privileges](http://enterprise.arcgis.com/en/portal/latest/administer/windows/roles.htm) to run GeoAnalytics.\n",
    "- The big data file share name you are using. It is assumed you have already registered a big data file. If you haven't, you can register it manually using the [steps outlined here](http://enterprise.arcgis.com/en/server/latest/publish-services/windows/registering-your-data-with-arcgis-server-using-manager.htm#ESRI_SECTION1_0D55682C9D6E48E7857852A9E2D5D189), or using the API. [See this sample for details.](https://developers.arcgis.com/python/sample-notebooks/creating-hurricane-tracks-using-geoanalytics/#Create-a-data-store)\n",
    "- The dataset in the big data file share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that you can set to make this run on your own portal\n",
    "\n",
    "# This is the portal that you will be connecting to\n",
    "portal_url = \"https://mymachinename.domain.com/portal\"\n",
    "\n",
    "# This is the portal member and password that will be running analysis\n",
    "portal_username = \"username\"\n",
    "portal_password = \"password\"\n",
    "\n",
    "# The name of the big data file share used as input\n",
    "big_data_file_share_name = \"bigDataFileShares_pyTest\"\n",
    "\n",
    "# The dataset name in the big data file share above used to run the analysis\n",
    "big_data_file_share_dataset = \"ChicagoCrimes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up for the Enterprise portal\n",
    "\n",
    "gis = GIS(portal_url, portal_username, portal_password, verify_cert=False)\n",
    "if not arcgis.geoanalytics.is_supported():\n",
    "    print(\"GeoAnalytics is not supported on the Enterprise portal. Please use a portal that GeoAnalytics is supported on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the dataset to use for analysis\n",
    "To run analysis, we must find the dataset to run analysis on. In this workflow, we'll run the analysis on a dataset in a big data file share. Like all GeoAnalytics tools, this analysis could also be run on a feature layer or collection. To do this we first need to:\n",
    "- Find the big data file shares registered with our GeoAnalytics Server\n",
    "- Search through the big data file shares to find the one we want to use\n",
    "- Search through our big data file share for the dataset to use.\n",
    "\n",
    "Remember, you can have multiple big data file shares in a portal, and each big data file share may have one or more datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"bigDataFileShares_Joyce_BDFS\" type:Big Data File Share owner:Sarah_publisher>,\n",
       " <Item title:\"bigDataFileShares_createSpaceTimeCube\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_pyTest\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_test_outputs\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_findPointClusters\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_pytest-S3\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_holisticdata-azure\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_TestTaxi\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_Joyce_BDFS\" type:Big Data File Share owner:Sarah_publisher>,\n",
       " <Item title:\"bigDataFileShares_createSpaceTimeCube\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_orc_and_par\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_geocodeTesting\" type:Big Data File Share owner:admin>,\n",
       " <Item title:\"bigDataFileShares_pyTest\" type:Big Data File Share owner:admin>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for all the big data file shares in your portal\n",
    "bigdata_fileshares = gis.content.search(\"\", item_type = \"big data file share\", max_items=20)\n",
    "bigdata_fileshares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item being used is: <Item title:\"bigDataFileShares_pyTest\" type:Big Data File Share owner:admin>\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all the big data file share items until we find the one we are interested in using\n",
    "\n",
    "try: \n",
    "    data_item = next(x for x in bigdata_fileshares if x.title == big_data_file_share_name)\n",
    "    print(\"The item being used is: {0}\".format(data_item))\n",
    "except:\n",
    "    print(\"\\nThe big data file share that you were looking for was not found. Please:\")\n",
    "    print(\" - Verify you have registered the big data file share before running this code.\")\n",
    "    print(\" - Check that you gave the correct name for the big data file share. Expected format: \\\"bigDataFileShares_name\\\"\")\n",
    "    print(\" - Increase the max items returned when searching for your item.\\n\")\n",
    "    \n",
    "    print(\"The big data file shares listed in your portal are: \")\n",
    "    [print(\"  -\",x.title) for x in bigdata_fileshares]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The layer being used is: <Layer url:\"https://gpportal.esri.com/server/rest/services/DataStoreCatalogs/bigDataFileShares_pyTest/BigDataCatalogServer/ChicagoCrimes\">\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    layer_to_use = next(x for x in data_item.layers if x.properties.name == big_data_file_share_dataset)\n",
    "    print(\"The layer being used is: {0}\".format(layer_to_use))\n",
    "except:\n",
    "    print(\"\\nThe dataset: {0} in big data file share: {1} was not found. Please:\".format(big_data_file_share_dataset, big_data_file_share_name) )\n",
    "    print(\" - Check that you gave the correct name for the dataset and big data file share.\")\n",
    "    \n",
    "    print(\"The datasets listed in your big data file share are: \")\n",
    "    [print(\"  -\",x.properties.name) for x in data_item.layers]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Analysis\n",
    "Now that we have found the layer of interest we're able to set up the analysis envrionment and run the [Copy to Data Store](http://enterprise.arcgis.com/en/portal/latest/use/geoanalytics-copy-to-data-store.htm) tool using GeoAnalytics. When running tools, we can set environment variables that will be applied to all following tool runs. In this sample, we will set the following environment variables:\n",
    "\n",
    "- Default aggregation styles. We will set this to true, by default, it is set to false. \n",
    "- Verbose logging. We will turn this on to see the status of the tool as it runs.\n",
    "\n",
    "There are a few other parameters we could set ([see the API guide here](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.env.html)), but will not do for this sample. They include:\n",
    "\n",
    "- Processing spatial reference\n",
    "- Output data store\n",
    "- Output spatial reference\n",
    "- Extent of data used in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Copy to Data Store tool\n",
    "from arcgis.geoanalytics.manage_data import copy_to_data_store\n",
    "\n",
    "# Set the environment variables for using GeoAnalytics. All of these parameters are optional.\n",
    "arcgis.env.default_aggregation_styles = True\n",
    "arcgis.env.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted.\n",
      "Executing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing (CopyToDataStore): CopyToDataStore \"Record Set\" \"{\"serviceProperties\": {\"name\": \"CrimeDataset_38\", \"serviceUrl\": \"http://gpportal.esri.com/server/rest/services/Hosted/CrimeDataset_38/FeatureServer\"}, \"itemProperties\": {\"itemId\": \"15592be05cbc4b1a96512eab24414420\"}}\" \"{\"defaultAggregationStyles\": true}\"\n",
      "Start Time: Fri Jul 20 12:56:14 2018\n",
      "{\"messageCode\":\"BD_101081\",\"message\":\"Finished writing results:\"}\n",
      "{\"messageCode\":\"BD_101082\",\"message\":\"* Count of features = 271868\",\"params\":{\"resultCount\":\"271868\"}}\n",
      "{\"messageCode\":\"BD_101083\",\"message\":\"* Spatial extent = {\\\"xmin\\\":-87.93433083735326,\\\"ymin\\\":41.64472422641647,\\\"xmax\\\":-87.52468393341654,\\\"ymax\\\":42.022654058892584}\",\"params\":{\"extent\":\"{\\\"xmin\\\":-87.93433083735326,\\\"ymin\\\":41.64472422641647,\\\"xmax\\\":-87.52468393341654,\\\"ymax\\\":42.022654058892584}\"}}\n",
      "{\"messageCode\":\"BD_101084\",\"message\":\"* Temporal extent = Interval(MutableInstant(2014-01-01 00:00:00.000),MutableInstant(2014-12-31 23:58:00.000))\",\"params\":{\"extent\":\"Interval(MutableInstant(2014-01-01 00:00:00.000),MutableInstant(2014-12-31 23:58:00.000))\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     "{\"messageCode\":\"BD_101051\",\"message\":\"Possible issues were found while reading 'inputLayer'.\",\"params\":{\"paramName\":\"inputLayer\"}}\n",
      "{\"messageCode\":\"BD_101054\",\"message\":\"Some records have either missing or invalid geometries.\"}\n",
      "Succeeded at Fri Jul 20 12:58:41 2018 (Elapsed Time: 2 minutes 26 seconds)\n"
     ]
    }
   ],
   "source": [
    "# Run the tool. We use a random number generator to ensure the name is always unique.\n",
    "import random\n",
    "random_value = random.randint(1,100)\n",
    "\n",
    "result_name = \"CrimeDataset_\" + str(random_value)\n",
    "tool_output = copy_to_data_store(layer_to_use, output_name=result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ff809ba23c4a9f9455689a1dd40c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(basemaps=['dark-gray', 'dark-gray-vector', 'gray', 'gray-vector', 'hybrid', 'national-geographic', 'ocâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirm that a layer has been created\n",
    "\n",
    "processed_map = gis.map(\"Chicago\")\n",
    "processed_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_map.add_layer(tool_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the layer as a Map Image Layer\n",
    "\n",
    "The result of the GeoAnalytics tool is a feature layer in your portal. To create a map image layer you need to publish it. When you publish the layer, it will automatically create a map image layer in your portal of the same name, that aggregates depending on your zoom level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This publishes the feature layer as a map image layer\n",
    "self_aggregating_map_service = tool_output.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://gpportal.esri.com/portal/home/item.html?id=5e63183d5ea44ffc8c8b6f7d7d7d9b96' target='_blank'>\n",
       "                        <img src='https://gpportal.esri.com/portal/portalimages/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://gpportal.esri.com/portal/home/item.html?id=5e63183d5ea44ffc8c8b6f7d7d7d9b96' target='_blank'><b>CrimeDataset_38</b>\n",
       "                        </a>\n",
       "                        <br/>CrimeDataset_38<img src='https://gpportal.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/mapimages16.png' style=\"vertical-align:middle;\">Map Image Layer by admin\n",
       "                        <br/>Last Modified: July 20, 2018\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"CrimeDataset_38\" type:Map Image Layer owner:admin>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_aggregating_map_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
